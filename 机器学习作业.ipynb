{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多元线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 506,     特征的个数 = 13\n",
      "Boston房价数据集描述: .. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的波士顿房价数据集\n",
    "from sklearn.datasets import load_boston\n",
    "X,y=load_boston(return_X_y=True)\n",
    "print(\"样本的个数 = {},     特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "print(\"Boston房价数据集描述:\",load_boston().DESCR)\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多元线性回归模型拟合的均方误差为:24.769\n",
      "多元线性回归可以解释原变量60.536%的信息\n"
     ]
    }
   ],
   "source": [
    "# 导入多元线性回归函数\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_lr=LinearRegression()  # 模型实例化\n",
    "# 模型训练及预测\n",
    "model_lr=model_lr.fit(X_train,y_train)\n",
    "y_pred=model_lr.predict(X_test)\n",
    "# 模型评价：采用MSE和R^2来进行评价\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "MSE=mean_squared_error(y_pred,y_test)\n",
    "r2=r2_score(y_pred,y_test)\n",
    "print(\"多元线性回归模型拟合的均方误差为:{}\".format(round(MSE,3)))\n",
    "print(\"多元线性回归可以解释原变量%.3f%%的信息\"% (r2 *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多项式回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 506,    特征的个数 = 13\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的波士顿房价数据集\n",
    "from sklearn.datasets import load_boston\n",
    "X,y=load_boston(return_X_y=True)\n",
    "print(\"样本的个数 = {},    特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多项式回归模型拟合的均方误差为:13.787\n",
      "多项式回归可以解释原变量81.615%的信息\n"
     ]
    }
   ],
   "source": [
    "# 导入线性回归函数和将特征生成多项式的函数，并将其结合为pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "poly=PolynomialFeatures(degree=3)  # 将degree设为3,3次多项式\n",
    "model_poly=make_pipeline(PolynomialFeatures(degree=2),LinearRegression())\n",
    "# 模型训练及预测\n",
    "model_poly=model_poly.fit(X_train,y_train)\n",
    "y_pred=model_poly.predict(X_test)\n",
    "# 模型评价：采用MSE和R^2来进行评价\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "MSE=mean_squared_error(y_pred,y_test)\n",
    "r2=r2_score(y_pred,y_test)\n",
    "print(\"多项式回归模型拟合的均方误差为:{}\".format(round(MSE,3)))\n",
    "print(\"多项式回归可以解释原变量%.3f%%的信息\"% (r2 *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 判别分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       1.00      0.99      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "逻辑回归模型拟合的准确率为:99.301%\n"
     ]
    }
   ],
   "source": [
    "# 导入逻辑回归函数\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logistic=LogisticRegression()\n",
    "# 模型训练及预测\n",
    "model_logistic=model_logistic.fit(X_train,y_train)\n",
    "y_pred=model_logistic.predict(X_test)\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"逻辑回归模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## probit回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025016\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025131\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025012\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025116\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025107\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025164\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025122\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025196\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025152\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025071\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025211\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025129\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025205\n",
      "         Iterations 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025227\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025084\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025115\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025114\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024992\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025273\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025327\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025335\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025167\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025084\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025018\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025062\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025127\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025104\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025074\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025203\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025023\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025071\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025076\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025104\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025118\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025116\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025187\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025346\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025158\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025202\n",
      "         Iterations 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 21\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025192\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025032\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025173\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025163\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025054\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025382\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025132\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025289\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025205\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025313\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025331\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025339\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025140\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025197\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025313\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025055\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025138\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025377\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025356\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025447\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025332\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025109\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025395\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025128\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025183\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025335\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025340\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024960\n",
      "         Iterations 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025337\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025063\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025623\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025076\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 22\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025284\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025113\n",
      "         Iterations 18\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.025386\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025084\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025053\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025322\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025297\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024943\n",
      "         Iterations 18\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.025198\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025290\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025070\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025232\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025047\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025283\n",
      "         Iterations 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 33\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025290\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025222\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025254\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025293\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025155\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025090\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025323\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025368\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025315\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024761\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025161\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025421\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025290\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025334\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025378\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025130\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025254\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025310\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024764\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025268\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025355\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025304\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025421\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025388\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025291\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025309\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025380\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025158\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025072\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025205\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025313\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025124\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024893\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025281\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025349\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025326\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025171\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025137\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025283\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025083\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025341\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025153\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025197\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025260\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025107\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025298\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025308\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025055\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025295\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025411\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025174\n",
      "         Iterations 18\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.025338\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025296\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025365\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025424\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025202\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025378\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025113\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025317\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025291\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025399\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025699\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025342\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025261\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025297\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025125\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024478\n",
      "         Iterations 22\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025335\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025364\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025351\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025058\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024985\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025327\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025009\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025324\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025371\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025163\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024995\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025311\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025318\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025162\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025125\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025378\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025406\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025435\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025494\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025172\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025353\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025366\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024891\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025056\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025153\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025339\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025369\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025192\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025276\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025346\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025365\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 18\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.025347\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025479\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025172\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025320\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025122\n",
      "         Iterations 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025201\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025152\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025126\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025274\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025170\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024923\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025090\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025255\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025219\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025352\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025176\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025271\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025041\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025333\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024210\n",
      "         Iterations 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025192\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024970\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025313\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025356\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025029\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025046\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025316\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025313\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025354\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025126\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025280\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025364\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025304\n",
      "         Iterations 17\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.205751\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.025194\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025148\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025333\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025304\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025063\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025356\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025303\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024937\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025107\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025054\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025293\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025344\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025273\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025299\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025159\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025306\n",
      "         Iterations 17\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.025329\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025296\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025283\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025324\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024972\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025299\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025008\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025160\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025068\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025225\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025055\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025175\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025013\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025090\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025076\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025234\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025123\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020671\n",
      "         Iterations 33\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025133\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024933\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025328\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025336\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025306\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025388\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025377\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025344\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024949\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025375\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025183\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025099\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025379\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025204\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025302\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025285\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025052\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025254\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025085\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025192\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025326\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025378\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025323\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025365\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 16\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025342\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025509\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025273\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025298\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025311\n",
      "         Iterations 17\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.025361\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025349\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025422\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025302\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025344\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024949\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025355\n",
      "         Iterations 17\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.024999\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025361\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025347\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025332\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025356\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025387\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025367\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025339\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025318\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025299\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025339\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025369\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025547\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025369\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025378\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025161\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025359\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025390\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025340\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025133\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025294\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024983\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025322\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025345\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025328\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025350\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025135\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025231\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025194\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025310\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025378\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025353\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025338\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025056\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025391\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025084\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025336\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024882\n",
      "         Iterations 18\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.866361\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025313\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025301\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025050\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025294\n",
      "         Iterations 17\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.025409\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025329\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 22\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025335\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025378\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025342\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025182\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024885\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025108\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025382\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025317\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025320\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025316\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025368\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025270\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025352\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025321\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025321\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025257\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025336\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025114\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025020\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025281\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024926\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024966\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025066\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025350\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025165\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025083\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025315\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025325\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025403\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025289\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025323\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025208\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025262\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025343\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025374\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025348\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025345\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025225\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025325\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025330\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025441\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025108\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025353\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025452\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025067\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025026\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025307\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025317\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025254\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025335\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025327\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025309\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025102\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025316\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025338\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025305\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025341\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025276\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025265\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025346\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025160\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025271\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025227\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025290\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025369\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024550\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025209\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025298\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025345\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024911\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025344\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025316\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025328\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025299\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025299\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025273\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025340\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025341\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025308\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025263\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025372\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025341\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025165\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025416\n",
      "         Iterations 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025098\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025051\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025298\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025151\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025299\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025301\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025305\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025334\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025267\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025130\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025350\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025425\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025230\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025256\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025063\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025296\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024716\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025048\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025388\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025113\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025308\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025296\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025281\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025268\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025293\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025313\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025325\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025043\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024053\n",
      "         Iterations 19\n",
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.025310\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025311\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025305\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022812\n",
      "         Iterations 22\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025254\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025364\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025083\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025290\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025319\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025296\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025276\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025380\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025343\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025304\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025117\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025347\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025315\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025234\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025314\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025263\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025298\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025288\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025297\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025335\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025268\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025041\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025295\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025208\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025271\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025269\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025141\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025442\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025328\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025263\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025256\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025286\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025105\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025045\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025278\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025202\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025316\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024857\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025388\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025472\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025309\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025375\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025280\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025168\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025353\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025323\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025139\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025262\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025229\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025295\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025098\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025097\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025292\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025318\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025314\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024949\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025353\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025281\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025339\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025332\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025263\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025304\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024227\n",
      "         Iterations 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025316\n",
      "         Iterations 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025288\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025300\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025071\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025332\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025060\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024626\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025303\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025426\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025390\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025386\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025234\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025263\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025264\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025338\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025274\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025367\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025387\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025360\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025315\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025418\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025339\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025273\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025403\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025295\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025323\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025387\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025411\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025297\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025304\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025297\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025386\n",
      "         Iterations 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025011\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024978\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024851\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025014\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025182\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024958\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025415\n",
      "         Iterations 18\n",
      "Accuracy的个数为：(569,)\n",
      "使用留一法划分数据集的Probit模型拟合的平均准确率为:96.309%\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留一法划分数据集\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo=LeaveOneOut()\n",
    "Accuracy=[]\n",
    "# loo.split():这里拆分的是index\n",
    "for train_index,test_index in loo.split(X):\n",
    "    X_train,X_test=X[train_index],X[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    # 将数据进行标准化\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler=StandardScaler().fit(X_train)\n",
    "    X_train=scaler.transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "    # 导入Probit回归函数\n",
    "    from statsmodels.discrete.discrete_model import Probit\n",
    "    import statsmodels.api as sm\n",
    "    model = Probit(y_train, X_train)\n",
    "    probit_model = model.fit()\n",
    "    y_pred=probit_model.predict(X_test)\n",
    "    y_pred=(y_pred>=0.5)*1\n",
    "    # 模型评价\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    Acc=accuracy_score(y_pred,y_test)\n",
    "    Accuracy.append(Acc)\n",
    "print(\"Accuracy的个数为：{}\".format(np.array(Accuracy).shape))\n",
    "print(\"使用留一法划分数据集的Probit模型拟合的平均准确率为:%.3f%%\"% (np.mean(Accuracy) *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24197072],\n",
       "       [0.05399097],\n",
       "       [0.00443185]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=np.array([1,2,3])\n",
    "z=z.reshape(3,1)\n",
    "f(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义probit回归的激活函数(标准正态分布的分布函数)\n",
    "from scipy import integrate\n",
    "import math\n",
    "import numpy as np\n",
    "# 定义标准正态分布的概率密度函数\n",
    "def f(x):\n",
    "    p=(np.exp(-x**2/2))/(math.sqrt(2*math.pi))\n",
    "    return p\n",
    "# 定义标准正态分布的分布函数（即Probit回归的激活函数）\n",
    "def F(x):\n",
    "    return integrate.quad(f,-np.inf,x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def networks(X):\n",
    "    nums=X.shape[0]\n",
    "    dims=X.shape[1]\n",
    "    return nums,dims\n",
    "\n",
    "def initialize_params(dims):\n",
    "    W=np.random.randint(0,5,(dims,1))*0.001\n",
    "    W=np.squeeze(W)\n",
    "    b=1\n",
    "    return W,b\n",
    "\n",
    "def probit(X,y,W,b,nums):\n",
    "    z=np.dot(X,W)+b\n",
    "    z=np.squeeze(z)\n",
    "    p=f(z)\n",
    "    y_pred=[]\n",
    "    for i in list(z):\n",
    "        y_p=F(i)\n",
    "        y_pred.append(y_p)\n",
    "    y_pred=np.array(y_pred)\n",
    "    #print(y_pred)\n",
    "    cost=-1/nums*np.sum(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    dW=-1/nums*(np.dot(X.T,p*(y-z)/(z*(1-z))))\n",
    "    db=-np.sum(p*(y-z)/(z*(1-z)))/nums\n",
    "    cost=np.squeeze(cost)\n",
    "    dW=np.squeeze(dW)\n",
    "    return y_pred,cost,dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.99982207, 1.        ,\n",
       "       0.99997975, 1.        , 0.99999882, 0.99998341, 0.9999761 ,\n",
       "       0.99999999, 1.        , 1.        , 0.99999843, 0.99997396,\n",
       "       0.99999957, 0.99999998, 1.        , 1.        , 0.99996559,\n",
       "       0.99989028, 0.99423877, 0.99999973, 1.        , 1.        ,\n",
       "       1.        , 0.99999881, 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.99999843, 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.99999434, 0.99965809, 0.99998922, 0.99998109,\n",
       "       0.99998969, 0.99958492, 1.        , 0.99999862, 0.99998002,\n",
       "       1.        , 0.98791556, 0.99998518, 0.99978418, 0.99996643,\n",
       "       0.99957682, 0.99992455, 0.99954721, 1.        , 0.99999984,\n",
       "       0.99945386, 1.        , 0.99999971, 0.99989666, 0.99036975,\n",
       "       0.99736421, 0.99261705, 0.99999972, 0.99465931, 0.99999838,\n",
       "       0.99999927, 0.99596382, 0.99908335, 0.99533112, 0.99968926,\n",
       "       1.        , 0.99295618, 1.        , 0.99999297, 0.99985215,\n",
       "       1.        , 0.99985786, 1.        , 1.        , 0.99988501,\n",
       "       0.99963847, 0.99987546, 1.        , 1.        , 0.99973983,\n",
       "       1.        , 0.99999524, 1.        , 0.99981414, 0.99999411,\n",
       "       0.99999386, 0.99999597, 0.99999461, 0.99996395, 0.99999988,\n",
       "       1.        , 0.99941194, 0.99714833, 0.99940339, 0.99999573,\n",
       "       0.99999893, 0.97853099, 0.99969677, 0.99697752, 0.99819298,\n",
       "       0.99999474, 0.99960044, 0.99964596, 1.        , 0.99954209,\n",
       "       0.99717907, 0.99965563, 0.99997771, 0.99753546, 0.99216736,\n",
       "       0.99980773, 0.99169739, 0.99999996, 1.        , 1.        ,\n",
       "       0.99933858, 1.        , 1.        , 0.99997956, 0.99989031,\n",
       "       0.99997215, 0.9999968 , 1.        , 0.99998918, 1.        ,\n",
       "       0.99965019, 0.99999999, 0.99999999, 0.99999889, 1.        ,\n",
       "       0.99993083, 0.99972534, 0.99898164, 0.99999986, 0.99866433,\n",
       "       0.99532425, 1.        , 0.99946257, 0.9999102 , 0.99869113,\n",
       "       0.99949435, 0.99984205, 0.99999504, 0.99998667, 0.99997143,\n",
       "       0.99989633, 0.99013657, 0.99808945, 0.99857207, 0.99994497,\n",
       "       0.9997325 , 1.        , 0.9999999 , 0.99953315, 0.99899199,\n",
       "       0.99975164, 1.        , 1.        , 0.99974179, 1.        ,\n",
       "       0.99998865, 0.9978267 , 1.        , 1.        , 0.99999121,\n",
       "       0.99963666, 0.99999971, 0.99999996, 0.99778698, 0.9981209 ,\n",
       "       0.98944066, 0.99801079, 0.99999975, 0.9998554 , 0.99973588,\n",
       "       1.        , 1.        , 1.        , 0.99907482, 0.99999949,\n",
       "       0.99866366, 1.        , 0.9995209 , 0.99930896, 0.9996538 ,\n",
       "       0.99999124, 0.99986709, 0.9943098 , 0.99999029, 0.99999379,\n",
       "       0.99983139, 0.99999627, 1.        , 1.        , 0.99999984,\n",
       "       0.99991402, 1.        , 1.        , 0.99999999, 0.99995056,\n",
       "       0.9999996 , 0.99556113, 1.        , 0.99992294, 0.99999874,\n",
       "       1.        , 0.99965806, 1.        , 0.99999992, 0.99999589,\n",
       "       0.99998405, 0.99964375, 0.99821342, 1.        , 1.        ,\n",
       "       0.99995803, 0.99995166, 0.99730143, 0.99999995, 0.99996601,\n",
       "       0.99999781, 0.99765036, 0.99999325, 0.99989455, 0.99997332,\n",
       "       0.99999999, 0.99902097, 0.99932396, 1.        , 0.99531045,\n",
       "       0.99997326, 1.        , 1.        , 0.99999089, 1.        ,\n",
       "       0.99994878, 0.99958432, 0.99929915, 0.99997432, 1.        ,\n",
       "       0.99832218, 0.99984162, 0.99991247, 0.99908942, 0.99930419,\n",
       "       1.        , 0.99949887, 1.        , 1.        , 1.        ,\n",
       "       0.99999515, 1.        , 0.99999951, 1.        , 0.99999992,\n",
       "       1.        , 1.        , 1.        , 0.99999966, 1.        ,\n",
       "       1.        , 0.9986994 , 0.99994856, 0.99983058, 0.99841748,\n",
       "       0.99994168, 0.99880729, 1.        , 0.99641491, 1.        ,\n",
       "       0.99938294, 0.99888837, 1.        , 0.99997766, 0.99994178,\n",
       "       1.        , 0.99964802, 1.        , 0.99999988, 0.99983853,\n",
       "       0.99974179, 0.99973109, 0.99972803, 0.99898159, 0.99905919,\n",
       "       0.99999375, 0.99999409, 0.99979269, 0.99951473, 0.99966756,\n",
       "       0.99992122, 0.99741003, 0.99977753, 0.99999346, 0.99719889,\n",
       "       1.        , 0.99973815, 1.        , 0.99723278, 0.99934934,\n",
       "       0.99932241, 0.99988957, 0.99198533, 0.99995116, 0.99993989,\n",
       "       0.99924734, 0.99999523, 0.99986814, 0.99888311, 0.98899202,\n",
       "       0.99960943, 0.99940875, 1.        , 0.99472858, 0.99955703,\n",
       "       0.99777034, 1.        , 0.99983282, 1.        , 0.99978919,\n",
       "       0.99976436, 0.99997857, 0.99952615, 0.99999998, 0.99999975,\n",
       "       0.99999993, 0.99991038, 0.99879314, 0.9992805 , 0.99965835,\n",
       "       1.        , 0.99974383, 1.        , 0.99765834, 1.        ,\n",
       "       0.99999719, 0.99648276, 0.99864894, 1.        , 0.99950625,\n",
       "       0.99679084, 0.99973453, 0.9999977 , 0.99909246, 0.99940314,\n",
       "       0.9996337 , 0.99999938, 1.        , 0.99999995, 0.99896238,\n",
       "       0.99973085, 0.99984922, 0.99995897, 0.99441391, 0.99878865,\n",
       "       0.99980762, 0.99989841, 0.99979343, 0.99999979, 0.99992312,\n",
       "       1.        , 1.        , 0.99988125, 1.        , 1.        ,\n",
       "       0.99999999, 0.99999218, 1.        , 1.        , 0.99993632,\n",
       "       0.99999687, 0.99682882, 0.99995641, 0.99992048, 0.99956496,\n",
       "       0.99918929, 0.99875251, 0.99939989, 0.9998499 , 0.99987654,\n",
       "       0.99998892, 0.99959601, 0.99997808, 0.99893788, 1.        ,\n",
       "       0.99745412, 0.99517824, 1.        , 1.        , 0.99974503,\n",
       "       0.99994912, 0.99994952, 0.9998424 , 0.99925706, 0.99973757,\n",
       "       1.        , 0.99978085, 0.99989388, 0.99977859, 0.99961767,\n",
       "       0.9992657 , 0.99999922, 0.99993582, 1.        , 0.99987153,\n",
       "       0.99958865, 0.99912217, 0.99411721, 0.99999784, 0.99999943,\n",
       "       0.99959299, 0.99724827, 1.        , 0.99971749, 0.9990896 ,\n",
       "       0.99958089, 0.99999565, 0.99916736, 0.9999688 , 0.99803427,\n",
       "       0.9973336 , 0.99879807, 0.99940586, 0.99822493, 0.99980799,\n",
       "       0.99999725, 0.99956416, 1.        , 1.        , 0.99998778,\n",
       "       0.99999745, 0.99990375, 0.99998332, 0.99998416, 0.99995054,\n",
       "       0.99933317, 1.        , 0.99996439, 0.99698512, 1.        ,\n",
       "       0.99957879, 1.        , 0.99999434, 0.99999537, 1.        ,\n",
       "       0.99952299, 1.        , 0.99964241, 0.99998159, 0.99988061,\n",
       "       0.99997651, 0.99969768, 0.99991219, 0.99990593, 0.99686615,\n",
       "       1.        , 1.        , 0.99998113, 0.99933568, 0.99994795,\n",
       "       0.99998288, 0.99996229, 0.9974982 , 1.        , 0.99965723,\n",
       "       0.99769631, 0.99984443, 0.99999825, 0.99981565, 0.99853343,\n",
       "       0.99983318, 0.9999959 , 0.99996765, 0.99909138, 0.99999947,\n",
       "       0.99969957, 0.99999479, 0.9999181 , 0.99995219, 0.99999581,\n",
       "       0.99984335, 0.99999461, 1.        , 0.99969825, 0.99999994,\n",
       "       0.99989172, 1.        , 1.        , 0.99958798, 0.99993154,\n",
       "       0.99999058, 0.99989843, 0.99984384, 1.        , 1.        ,\n",
       "       0.99999711, 0.99999371, 0.99969293, 1.        , 0.99417809,\n",
       "       0.99552711, 0.99951577, 0.99817845, 0.99999876, 0.99999924,\n",
       "       0.99909409, 0.99998269, 0.99999692, 0.99999694, 0.99999957,\n",
       "       0.99919912, 1.        , 1.        , 0.99995559, 0.99989532,\n",
       "       0.99527435, 1.        , 0.99863858, 0.99996762, 0.99734793,\n",
       "       0.99105114, 0.99997079, 0.99968095, 0.99994051, 0.99964183,\n",
       "       0.99975388, 0.99969481, 0.99998404, 1.        , 0.99821464,\n",
       "       1.        , 0.99998145, 0.99947358, 0.99037339, 0.98744029,\n",
       "       0.99899712, 0.99999498, 0.99999579, 0.99991677, 0.99995994,\n",
       "       0.99997914, 0.99739992, 0.99651312, 0.99699451, 0.99956908,\n",
       "       0.99836088, 0.99883821, 0.99985863, 0.9939731 , 0.99986036,\n",
       "       0.99726929, 0.99640159, 0.99664333, 0.99998181, 0.9993647 ,\n",
       "       0.99997653, 0.99904557, 0.99999945, 1.        , 1.        ,\n",
       "       1.        , 0.99999999, 1.        , 0.99195179])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums,dims=networks(X_train)\n",
    "W,b=initialize_params(dims)\n",
    "W=np.squeeze(W)\n",
    "y_pred,cost,dW,db=probit(X,y,W,b,nums)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Probit_train(X,y,lr,epochs):\n",
    "    nums,dims=networks(X)\n",
    "    W,b=initialize_params(dims)\n",
    "    for i in range(epochs):\n",
    "        y_pred,cost,dW,db=probit(X,y,W,b,nums)\n",
    "        W=W-lr*dW\n",
    "        b=b-lr*db\n",
    "        for j in range(len(y_pred)):\n",
    "            if y_pred[j]>0.5:\n",
    "                y_pred[j]=1\n",
    "            else:\n",
    "                y_pred[j]=0\n",
    "        acc=(y_pred==y).sum()/nums\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print('epoch: {}, Loss: {:.5f}, Acc: {:.5f}'.format(i+1, cost, acc))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in multiply\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, Loss: nan, Acc: 0.21596\n",
      "epoch: 40, Loss: nan, Acc: 0.21596\n",
      "epoch: 60, Loss: nan, Acc: 0.21596\n",
      "epoch: 80, Loss: nan, Acc: 0.22066\n",
      "epoch: 100, Loss: nan, Acc: 0.22300\n",
      "epoch: 120, Loss: nan, Acc: 0.22300\n",
      "epoch: 140, Loss: nan, Acc: 0.22300\n",
      "epoch: 160, Loss: nan, Acc: 0.22300\n",
      "epoch: 180, Loss: nan, Acc: 0.22300\n",
      "epoch: 200, Loss: nan, Acc: 0.22300\n",
      "epoch: 220, Loss: nan, Acc: 0.22300\n",
      "epoch: 240, Loss: nan, Acc: 0.22535\n",
      "epoch: 260, Loss: nan, Acc: 0.22535\n",
      "epoch: 280, Loss: nan, Acc: 0.22535\n",
      "epoch: 300, Loss: nan, Acc: 0.22535\n",
      "epoch: 320, Loss: nan, Acc: 0.22770\n",
      "epoch: 340, Loss: nan, Acc: 0.22770\n",
      "epoch: 360, Loss: nan, Acc: 0.22770\n",
      "epoch: 380, Loss: nan, Acc: 0.22770\n",
      "epoch: 400, Loss: nan, Acc: 0.22770\n",
      "epoch: 420, Loss: nan, Acc: 0.22770\n",
      "epoch: 440, Loss: nan, Acc: 0.23005\n",
      "epoch: 460, Loss: nan, Acc: 0.22770\n",
      "epoch: 480, Loss: nan, Acc: 0.22770\n",
      "epoch: 500, Loss: nan, Acc: 0.22770\n",
      "epoch: 520, Loss: nan, Acc: 0.22770\n",
      "epoch: 540, Loss: nan, Acc: 0.22770\n",
      "epoch: 560, Loss: nan, Acc: 0.22770\n",
      "epoch: 580, Loss: nan, Acc: 0.23005\n",
      "epoch: 600, Loss: nan, Acc: 0.23005\n",
      "epoch: 620, Loss: nan, Acc: 0.22535\n",
      "epoch: 640, Loss: nan, Acc: 0.23005\n",
      "epoch: 660, Loss: nan, Acc: 0.23239\n",
      "epoch: 680, Loss: nan, Acc: 0.23474\n",
      "epoch: 700, Loss: nan, Acc: 0.23474\n",
      "epoch: 720, Loss: nan, Acc: 0.23239\n",
      "epoch: 740, Loss: nan, Acc: 0.23239\n",
      "epoch: 760, Loss: nan, Acc: 0.23474\n",
      "epoch: 780, Loss: nan, Acc: 0.23709\n",
      "epoch: 800, Loss: nan, Acc: 0.23709\n",
      "epoch: 820, Loss: nan, Acc: 0.23709\n",
      "epoch: 840, Loss: nan, Acc: 0.23709\n",
      "epoch: 860, Loss: nan, Acc: 0.23709\n",
      "epoch: 880, Loss: nan, Acc: 0.23709\n",
      "epoch: 900, Loss: nan, Acc: 0.23944\n",
      "epoch: 920, Loss: nan, Acc: 0.23944\n",
      "epoch: 940, Loss: nan, Acc: 0.23944\n",
      "epoch: 960, Loss: nan, Acc: 0.24178\n",
      "epoch: 980, Loss: nan, Acc: 0.24178\n",
      "epoch: 1000, Loss: nan, Acc: 0.24178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=1\n",
    "epochs=1000\n",
    "Probit_train(X_train,y_train,lr,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n"
     ]
    }
   ],
   "source": [
    "nums,dims=networks(X)\n",
    "W,b=initialize_params(dims)\n",
    "print(W.shape)\n",
    "y_pred,cost,dW,db=probit(X,y,W,b,nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.48392498e+01 -6.48392498e+01 -6.48392498e+01 ... -6.48392498e+01\n",
      "  -6.48392498e+01 -3.01837620e+00]\n",
      " [-9.50367977e+01 -9.50367977e+01 -9.50367977e+01 ... -9.50367977e+01\n",
      "  -9.50367977e+01 -4.15925648e+00]\n",
      " [-4.19497507e+02 -4.19497507e+02 -4.19497507e+02 ... -4.19497507e+02\n",
      "  -4.19497507e+02 -1.96331750e+01]\n",
      " ...\n",
      " [-4.74102429e-01 -4.74102429e-01 -4.74102429e-01 ... -4.74102429e-01\n",
      "  -4.74102429e-01 -2.41980599e-02]\n",
      " [-1.44767308e+00 -1.44767308e+00 -1.44767308e+00 ... -1.44767308e+00\n",
      "  -1.44767308e+00 -6.26715984e-02]\n",
      " [-4.25771435e-01 -4.25771435e-01 -4.25771435e-01 ... -4.25771435e-01\n",
      "  -4.25771435e-01 -1.81664104e-02]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2c37a6882a85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-4847714aef3c>\u001b[0m in \u001b[0;36mprobit\u001b[1;34m(X, y, W, b, nums)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mcost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdelta_W\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-8b19103c9818>\u001b[0m in \u001b[0;36mF\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# 定义标准正态分布的分布函数（即Probit回归的激活函数）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mintegrate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\kw\\Anaconda3\\lib\\site-packages\\scipy\\integrate\\quadpack.py\u001b[0m in \u001b[0;36mquad\u001b[1;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;31m# check the limits of integration: \\int_a^b, expect a < b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[0mflip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    y_pred,cost,dW,db=probit(X,y,W,b,nums)\n",
    "    print(dW)\n",
    "    W=W-lr*dW\n",
    "    b=b-lr*db\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i]>0.5:\n",
    "            y_pred[i]=1\n",
    "        else:\n",
    "            y_pred[i]=0\n",
    "    acc=(y_pred==y).sum()/nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_tensor(X):\n",
    "    return torch.tensor(X,dtype=torch.float32)\n",
    "\n",
    "def networks(X):\n",
    "    nums=X.shape[0]\n",
    "    dims=X.shape[1]\n",
    "    return nums,dims\n",
    "\n",
    "def initialize_params(dims):\n",
    "    W=torch.rand((dims,1),requires_grad=True)\n",
    "    b=torch.zeros((1),requires_grad=True)\n",
    "    return W,b\n",
    "\n",
    "def forward(X,y,W,b,lr):\n",
    "    z=torch.mm(X,W)+b\n",
    "    z=z.data.numpy()\n",
    "    y_pred=[]\n",
    "    for k in list(z):\n",
    "        z_pred=F(k)\n",
    "        y_pred.append(z_pred)\n",
    "    y_pred=torch.tensor(np.array(y_pred))\n",
    "    L=-(y * torch.log(y_pred) + (1 - y) * torch.log(1-y_pred)).mean()\n",
    "    return y_pred,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Probit(X,y):\n",
    "    nums,dims=networks(X)\n",
    "    W,b=initialize_params(dims)\n",
    "    lr=0.01\n",
    "    for i in range(2):\n",
    "        z=torch.mm(X,W)+b\n",
    "        z=z.data.numpy()\n",
    "        y_pred=[]\n",
    "        for k in list(z):\n",
    "            z_pred=F(k)\n",
    "            y_pred.append(z_pred)\n",
    "        y_pred=torch.tensor(np.array(y_pred))\n",
    "        L=-(y * torch.log(y_pred) + (1 - y) * torch.log(1-y_pred)).mean()\n",
    "        L.backward()\n",
    "        W.data=W.data-lr*W.grad.data\n",
    "        b.data=b.data-lr*b.grad.data\n",
    "        mask = y_pred.ge(0.5).float()\n",
    "        acc = (mask == y.data).sum().data[0] / y.data.shape[0]\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print('epoch: {}, Loss: {:.5f}, Acc: {:.5f}'.format(i+1, L.data[0], acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:300: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.discrete.discrete_model import Probit\n",
    "import statsmodels.api as sm\n",
    "model = Probit(y_train, X_train)\n",
    "probit_model = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  512\n",
      "Model:                         Probit   Df Residuals:                      482\n",
      "Method:                           MLE   Df Model:                           29\n",
      "Date:                Fri, 24 Apr 2020   Pseudo R-squ.:                     nan\n",
      "Time:                        19:38:17   Log-Likelihood:                    nan\n",
      "converged:                       True   LL-Null:                       -336.61\n",
      "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const             nan        nan        nan        nan         nan         nan\n",
      "x1                nan        nan        nan        nan         nan         nan\n",
      "x2                nan        nan        nan        nan         nan         nan\n",
      "x3                nan        nan        nan        nan         nan         nan\n",
      "x4                nan        nan        nan        nan         nan         nan\n",
      "x5                nan        nan        nan        nan         nan         nan\n",
      "x6                nan        nan        nan        nan         nan         nan\n",
      "x7                nan        nan        nan        nan         nan         nan\n",
      "x8                nan        nan        nan        nan         nan         nan\n",
      "x9                nan        nan        nan        nan         nan         nan\n",
      "x10               nan        nan        nan        nan         nan         nan\n",
      "x11               nan        nan        nan        nan         nan         nan\n",
      "x12               nan        nan        nan        nan         nan         nan\n",
      "x13               nan        nan        nan        nan         nan         nan\n",
      "x14               nan        nan        nan        nan         nan         nan\n",
      "x15               nan        nan        nan        nan         nan         nan\n",
      "x16               nan        nan        nan        nan         nan         nan\n",
      "x17               nan        nan        nan        nan         nan         nan\n",
      "x18               nan        nan        nan        nan         nan         nan\n",
      "x19               nan        nan        nan        nan         nan         nan\n",
      "x20               nan        nan        nan        nan         nan         nan\n",
      "x21               nan        nan        nan        nan         nan         nan\n",
      "x22               nan        nan        nan        nan         nan         nan\n",
      "x23               nan        nan        nan        nan         nan         nan\n",
      "x24               nan        nan        nan        nan         nan         nan\n",
      "x25               nan        nan        nan        nan         nan         nan\n",
      "x26               nan        nan        nan        nan         nan         nan\n",
      "x27               nan        nan        nan        nan         nan         nan\n",
      "x28               nan        nan        nan        nan         nan         nan\n",
      "x29               nan        nan        nan        nan         nan         nan\n",
      "x30               nan        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:3917: RuntimeWarning: invalid value encountered in less\n",
      "  predclose_sum = (absprederror < 1e-4).sum()\n"
     ]
    }
   ],
   "source": [
    "print(probit_model.summary())\n",
    "y_pred=probit_model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性判别模型拟合的准确率为:98.246%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"线性判别模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X)\n",
    "X=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025199\n",
      "         Iterations 17\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  569\n",
      "Model:                         Probit   Df Residuals:                      539\n",
      "Method:                           MLE   Df Model:                           29\n",
      "Date:                Fri, 24 Apr 2020   Pseudo R-squ.:                  0.9618\n",
      "Time:                        19:28:52   Log-Likelihood:                -14.338\n",
      "converged:                       True   LL-Null:                       -375.72\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.736e-133\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           165.0808    109.766      1.504      0.133     -50.057     380.219\n",
      "x2            -1.0002      1.837     -0.544      0.586      -4.601       2.600\n",
      "x3           -98.6732     78.515     -1.257      0.209    -252.561      55.214\n",
      "x4           -62.3899     46.227     -1.350      0.177    -152.993      28.213\n",
      "x5            -9.2530      5.402     -1.713      0.087     -19.840       1.334\n",
      "x6            23.9561     15.102      1.586      0.113      -5.643      53.555\n",
      "x7            -4.7815      9.181     -0.521      0.602     -22.776      13.213\n",
      "x8            -8.3066      7.269     -1.143      0.253     -22.554       5.940\n",
      "x9             4.2066      3.008      1.398      0.162      -1.690      10.103\n",
      "x10           -1.2799      4.011     -0.319      0.750      -9.142       6.582\n",
      "x11           -9.3636     16.664     -0.562      0.574     -42.025      23.298\n",
      "x12            2.0860      2.347      0.889      0.374      -2.513       6.685\n",
      "x13           17.2965     12.695      1.362      0.173      -7.585      42.178\n",
      "x14          -35.0238     31.435     -1.114      0.265     -96.635      26.588\n",
      "x15           -0.7056      1.303     -0.541      0.588      -3.260       1.849\n",
      "x16          -14.9769      8.614     -1.739      0.082     -31.861       1.907\n",
      "x17           13.2890      7.832      1.697      0.090      -2.061      28.638\n",
      "x18          -14.6051      8.588     -1.701      0.089     -31.437       2.226\n",
      "x19            5.5035      3.737      1.473      0.141      -1.820      12.827\n",
      "x20           23.6099     13.970      1.690      0.091      -3.772      50.991\n",
      "x21          -67.9194     49.728     -1.366      0.172    -165.385      29.546\n",
      "x22           -6.6232      3.847     -1.722      0.085     -14.163       0.916\n",
      "x23          -20.7851     21.444     -0.969      0.332     -62.815      21.245\n",
      "x24           72.7658     56.076      1.298      0.194     -37.141     182.673\n",
      "x25            5.1621      4.239      1.218      0.223      -3.145      13.469\n",
      "x26           11.6643      7.686      1.518      0.129      -3.401      26.729\n",
      "x27          -16.2618      9.733     -1.671      0.095     -35.338       2.815\n",
      "x28            2.8470      3.107      0.916      0.360      -3.243       8.937\n",
      "x29           -8.7735      5.820     -1.507      0.132     -20.181       2.634\n",
      "x30          -13.8927      8.167     -1.701      0.089     -29.900       2.115\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.93 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "model = Probit(y, X)\n",
    "probit_model = model.fit()\n",
    "print(probit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(dims):\n",
    "    W=torch.rand((dims,1),requires_grad=True)\n",
    "    b=torch.zeros((1),requires_grad=True)\n",
    "    return W,b\n",
    "W,b=initialize_params(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cpu and dtype Double but got device cpu and dtype Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-e99c7133806b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected device cpu and dtype Double but got device cpu and dtype Float"
     ]
    }
   ],
   "source": [
    "z=torch.mm(X_train,W)+b\n",
    "z=z.data.numpy()\n",
    "y_pred=[]\n",
    "for k in list(z):\n",
    "    z_pred=F(k)\n",
    "    y_pred.append(z_pred)\n",
    "y_pred=torch.tensor(np.array(y_pred))\n",
    "L=-(y_train * torch.log(y_pred) + (1 - y_train) * torch.log(1-y_pred)).mean()\n",
    "L.backward()\n",
    "W.data=W.data-lr*W.grad.data\n",
    "b.data=b.data-lr*b.grad.data\n",
    "mask = y_pred.ge(0.5).float()\n",
    "acc = (mask == y.data).sum().data[0] / y.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([1,2,3])\n",
    "def F(x):\n",
    "    z,r=integrate.quad(f,-np.inf,x)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cpu and dtype Double but got device cpu and dtype Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-a3bab7c980eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mProbit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-77-6052e769f135>\u001b[0m in \u001b[0;36mProbit\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-e9e677b3cbaf>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(X, y, W, b, lr)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected device cpu and dtype Double but got device cpu and dtype Float"
     ]
    }
   ],
   "source": [
    "Probit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性判别分析（LDA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        51\n",
      "           1       1.00      0.97      0.98        92\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.97      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n",
      "线性判别模型拟合的准确率为:97.902%\n"
     ]
    }
   ],
   "source": [
    "# 导入线性判别函数：LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model_lda=LinearDiscriminantAnalysis()\n",
    "# 模型训练及预测\n",
    "model_lda=model_lda.fit(X_train,y_train)\n",
    "y_pred=model_lda.predict(X_test)\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"线性判别模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二次判别分析（QDA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       1.00      0.99      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "二次判别模型拟合的准确率为:99.301%\n"
     ]
    }
   ],
   "source": [
    "# 导入二次判别函数：QDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "model_qda=QuadraticDiscriminantAnalysis()\n",
    "# 模型训练及预测\n",
    "model_qda=model_qda.fit(X_train,y_train)\n",
    "y_pred=model_qda.predict(X_test)\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"二次判别模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K近邻（KNN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        53\n",
      "           1       0.99      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n",
      "K近邻模型拟合的准确率为:97.902%\n"
     ]
    }
   ],
   "source": [
    "# 导入K近邻函数：KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn=KNeighborsClassifier(n_neighbors=5)\n",
    "# 模型训练及预测\n",
    "model_knn=model_knn.fit(X_train,y_train)\n",
    "y_pred=model_knn.predict(X_test)\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"K近邻模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        49\n",
      "           1       1.00      0.95      0.97        94\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.95      0.97      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "高斯朴素贝叶斯模型拟合的准确率为:96.503%\n"
     ]
    }
   ],
   "source": [
    "# 导入高斯朴素贝叶斯函数\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_bayes=GaussianNB()\n",
    "# 模型训练及预测\n",
    "model_bayes=model_bayes.fit(X_train,y_train)\n",
    "y_pred=model_bayes.predict(X_test)\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"高斯朴素贝叶斯模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集划分及模型评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 留一法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "Accuracy的个数为：(569,)\n",
      "使用留一法划分数据集的高斯朴素贝叶斯模型拟合的平均准确率为:93.849%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留一法划分数据集\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo=LeaveOneOut()\n",
    "Accuracy=[]\n",
    "# loo.split():这里拆分的是index\n",
    "for train_index,test_index in loo.split(X):\n",
    "    X_train,X_test=X[train_index],X[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    model_bayes=model_bayes.fit(X_train,y_train)\n",
    "    y_pred=model_bayes.predict(X_test)\n",
    "    # 模型评价\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    Acc=accuracy_score(y_pred,y_test)\n",
    "    Accuracy.append(Acc)\n",
    "print(\"Accuracy的个数为：{}\".format(np.array(Accuracy).shape))\n",
    "print(\"使用留一法划分数据集的高斯朴素贝叶斯模型拟合的平均准确率为:%.3f%%\"% (np.mean(Accuracy) *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K折交叉验证法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "Accuracy的个数为：(10,)\n",
      "使用十折交叉验证法划分数据集的高斯朴素贝叶斯模型拟合的平均准确率为:93.678%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用交叉验证法划分数据集\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 进行10折交叉验证训练及评价\n",
    "scores=cross_val_score(model_bayes,X,y,cv=10)\n",
    "Acc=np.mean(scores)\n",
    "print(\"Accuracy的个数为：{}\".format(np.array(scores).shape))\n",
    "print(\"使用十折交叉验证法划分数据集的高斯朴素贝叶斯模型拟合的平均准确率为:%.3f%%\"% \n",
    "      \\n(np.mean(Acc) *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自助法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "使用自助法划分数据集的高斯朴素贝叶斯模型拟合的平均准确率为:93.897%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用自助法划分数据集(可重复抽样)\n",
    "X_train=pd.DataFrame(X).sample(frac=1.0,replace=True)\n",
    "X_test=pd.DataFrame(X).loc[pd.DataFrame(X).index.difference(X_train.index)].copy()\n",
    "y_train=y[X_train.index]\n",
    "y_test=y[X_test.index]\n",
    "# 模型训练及预测\n",
    "model_bayes=model_bayes.fit(np.array(X_train),y_train)\n",
    "y_pred=model_bayes.predict(np.array(X_test))\n",
    "# 模型评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"使用自助法划分数据集的高斯朴素贝叶斯模型拟合的平均准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC & AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20)\n"
     ]
    }
   ],
   "source": [
    "# 产生一个二分类数据集，n_samples=10000\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=10000)\n",
    "print(X.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.192256\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "# logistic回归\n",
    "model_logistic=model_logistic.fit(X_train,y_train)\n",
    "y_pred_logistic=model_logistic.predict_proba(X_test)[:,1]\n",
    "fpr_logistic, tpr_logistic,_= roc_curve(y_test, y_pred_logistic, pos_label=1)\n",
    "area_logistic=auc(fpr_logistic, tpr_logistic)\n",
    "# probit回归\n",
    "model = Probit(y_train, X_train)\n",
    "model_probit = model.fit()\n",
    "y_pred_probit=model_probit.predict(X_test)\n",
    "fpr_probit, tpr_probit,_= roc_curve(y_test, y_pred_probit, pos_label=1)\n",
    "area_probit=auc(fpr_probit, tpr_probit)\n",
    "# LDA\n",
    "model_lda=model_lda.fit(X_train,y_train)\n",
    "y_pred_lda=model_lda.predict_proba(X_test)[:,1]\n",
    "fpr_lda, tpr_lda,_= roc_curve(y_test, y_pred_lda, pos_label=1)\n",
    "area_lda=auc(fpr_lda, tpr_lda)\n",
    "# QDA\n",
    "model_qda=model_qda.fit(X_train,y_train)\n",
    "y_pred_qda=model_qda.predict_proba(X_test)[:,1]\n",
    "fpr_qda, tpr_qda,_= roc_curve(y_test, y_pred_qda, pos_label=1)\n",
    "area_qda=auc(fpr_qda, tpr_qda)\n",
    "# KNN\n",
    "model_knn=model_knn.fit(X_train,y_train)\n",
    "y_pred_knn=model_knn.predict_proba(X_test)[:,1]\n",
    "fpr_knn, tpr_knn,_= roc_curve(y_test, y_pred_knn, pos_label=1)\n",
    "area_knn=auc(fpr_knn, tpr_knn)\n",
    "# Gauss Navie Bayes\n",
    "model_bayes=model_bayes.fit(X_train,y_train)\n",
    "y_pred_bayes=model_bayes.predict_proba(X_test)[:,1]\n",
    "fpr_bayes, tpr_bayes,_= roc_curve(y_test, y_pred_bayes, pos_label=1)\n",
    "area_bayes=auc(fpr_bayes, tpr_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "# logistic回归\n",
    "y_pred_logistic=model_logistic.predict_proba(X_test)[:,1]\n",
    "fpr_logistic, tpr_logistic,_= roc_curve(y_test, y_pred_logistic, pos_label=1)\n",
    "area_logistic=auc(fpr_logistic, tpr_logistic)\n",
    "# probit回归\n",
    "model = Probit(y_train, X_train)\n",
    "model_probit = model.fit()\n",
    "y_pred_probit=model_probit.predict(X_test)\n",
    "fpr_probit, tpr_probit,_= roc_curve(y_test, y_pred_probit, pos_label=1)\n",
    "area_probit=auc(fpr_probit, tpr_probit)\n",
    "# LDA\n",
    "model_lda=model_lda.fit(X_train,y_train)\n",
    "y_pred_lda=model_lda.predict_proba(X_test)[:,1]\n",
    "fpr_lda, tpr_lda,_= roc_curve(y_test, y_pred_lda, pos_label=1)\n",
    "area_lda=auc(fpr_lda, tpr_lda)\n",
    "# QDA\n",
    "model_qda=model_qda.fit(X_train,y_train)\n",
    "y_pred_qda=model_qda.predict_proba(X_test)[:,1]\n",
    "fpr_qda, tpr_qda,_= roc_curve(y_test, y_pred_qda, pos_label=1)\n",
    "area_qda=auc(fpr_qda, tpr_qda)\n",
    "# KNN\n",
    "model_knn=model_knn.fit(X_train,y_train)\n",
    "y_pred_knn=model_knn.predict_proba(X_test)[:,1]\n",
    "fpr_knn, tpr_knn,_= roc_curve(y_test, y_pred_knn, pos_label=1)\n",
    "area_knn=auc(fpr_knn, tpr_knn)\n",
    "# Gauss Navie Bayes\n",
    "model_bayes=model_bayes.fit(X_train,y_train)\n",
    "y_pred_bayes=model_bayes.predict_proba(X_test)[:,1]\n",
    "fpr_bayes, tpr_bayes,_= roc_curve(y_test, y_pred_bayes, pos_label=1)\n",
    "area_bayes=auc(fpr_bayes, tpr_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(8,5))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_logistic,tpr_logistic,label=\"Logistic(auc = %0.3f)\" % area_logistic)\n",
    "plt.plot(fpr_probit,tpr_probit,label=\"Probit(auc = %0.3f)\" % area_probit)\n",
    "plt.plot(fpr_lda,tpr_lda,label=\"LDA(auc = %0.3f)\" % area_lda)\n",
    "plt.plot(fpr_qda,tpr_qda,label=\"QDA(auc = %0.3f)\" % area_qda)\n",
    "plt.plot(fpr_knn,tpr_knn,label=\"KNN(auc = %0.3f)\" % area_knn)\n",
    "plt.plot(fpr_bayes,tpr_bayes,label=\"Bayes(auc = %0.3f)\" % area_bayes)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征选择及降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最优子集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "\n",
    "def turnbits_rec(p):\n",
    "    if (p == 1):\n",
    "        return np.array([[True, False], [True, True]])\n",
    "    else:\n",
    "        tmp1 = np.c_[turnbits_rec(p - 1),\n",
    "                     np.array([False] * (2**(p - 1))).reshape((2**(p - 1), 1))]\n",
    "        tmp2 = np.c_[turnbits_rec(p - 1),\n",
    "                     np.array([True] * (2**(p - 1))).reshape((2**(p - 1), 1))]\n",
    "        return np.r_[tmp1, tmp2]\n",
    "\n",
    "def mse(xtx_t, xty_t, beta):\n",
    "    return (np.sum(np.dot(xtx_t, beta) * beta) - 2 * np.sum(xty_t * beta))\n",
    "\n",
    "def solve_sym(xtx, xty):\n",
    "    L = linalg.cholesky(xtx)\n",
    "    return linalg.lapack.dpotrs(L, xty)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestSubsetReg(object):\n",
    "    def __init__(self, x, y, inter=True, isCp=True, isAIC=True, isCV=True):\n",
    "        self.__n, self.__p = x.shape\n",
    "        if inter:\n",
    "            self.__x = np.c_[np.ones((self.__n, 1)), x]\n",
    "            self.__ind_var = turnbits_rec(self.__p)\n",
    "        else:\n",
    "            self.__x = x\n",
    "            self.__ind_var = turnbits_rec(self.__p)[:, 1:]\n",
    "        self.__y = y\n",
    "        self.__xTx = np.dot(self.__x.T, self.__x)\n",
    "        self.__xTy = np.dot(self.__x.T, self.__y)\n",
    "        self.__b = [\n",
    "            solve_sym(self.__xTx[ind][:, ind], self.__xTy[ind])\n",
    "            for ind in self.__ind_var\n",
    "        ]\n",
    "        self.__isCp = isCp\n",
    "        self.__isAIC = isAIC\n",
    "        self.__isCV = isCV\n",
    "\n",
    "    def __Cp_AIC(self):\n",
    "        rss = np.dot(self.__y, self.__y) - [\n",
    "            np.sum(np.dot(self.__xTx[ind][:, ind], b_) * b_)\n",
    "            for ind, b_ in zip(self.__ind_var, self.__b)\n",
    "        ]\n",
    "        d = np.sum(self.__ind_var, axis=1)\n",
    "        if self.__isCp:\n",
    "            self.Cp = rss + 2 * d * rss[-1] / (self.__n - self.__p - 1)\n",
    "        if self.__isAIC:\n",
    "            self.AIC = self.__n * np.log(rss) + 2 * d\n",
    "\n",
    "    def __cvreg(self):\n",
    "        K = 10\n",
    "        indexs = np.array_split(np.random.permutation(np.arange(0, self.__n)), K)\n",
    "\n",
    "        def cvk(ind, index):\n",
    "            txx = self.__xTx[ind][:, ind] - np.dot(\n",
    "                (self.__x[index][:, ind]).T, self.__x[index][:, ind])\n",
    "            txy = self.__xTy[ind] - np.dot(\n",
    "                (self.__x[index][:, ind]).T, self.__y[index])\n",
    "            tcoe = solve_sym(txx, txy)\n",
    "            return np.sum(\n",
    "                (self.__y[index] - np.dot(self.__x[index][:, ind], tcoe))**2)\n",
    "\n",
    "        self.cverr = np.sum(np.array([[cvk(ind, index) for index in indexs]\n",
    "                                      for ind in self.__ind_var]),\n",
    "                            axis=1) / self.__n\n",
    "\n",
    "    def output(self, isPrint=True):\n",
    "        \"\"\"\n",
    "        If inter=True, first item is intercept, Otherwise it is X1. \n",
    "        If print=False, save results only and do not print.\n",
    "        \"\"\"\n",
    "        if self.__isCp | self.__isAIC:\n",
    "            self.__Cp_AIC()\n",
    "            if self.__isCp:\n",
    "                min_id = np.argmin(self.Cp)\n",
    "                self.Cp = [self.__ind_var[min_id][0:], self.__b[min_id]]\n",
    "                if isPrint:\n",
    "                    print(\"Cp：\\nVariable：\", self.Cp[0])\n",
    "                    print(\"Coefficient：\", self.Cp[1])\n",
    "            if self.__isAIC:\n",
    "                min_id = np.argmin(self.AIC)\n",
    "                self.AIC = [self.__ind_var[min_id][0:], self.__b[min_id]]\n",
    "                if isPrint:\n",
    "                    print(\"AIC：\\nVariable：\", self.AIC[0])\n",
    "                    print(\"Coefficient：\", self.AIC[1])\n",
    "        if self.__isCV:\n",
    "            self.__cvreg()\n",
    "            min_id = np.argmin(self.cverr)\n",
    "            self.cverr = [self.__ind_var[min_id][0:], self.__b[min_id]]\n",
    "            if isPrint:\n",
    "                print(\"Cross Validation：\\nVariable：\", self.cverr[0])\n",
    "                print(\"Coefficient：\", self.cverr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 506,特征的个数 = 13\n",
      "Cp：\n",
      "Variable： [ True  True  True False  True  True  True False  True  True  True  True\n",
      "  True  True]\n",
      "Coefficient： [22.53280632 -0.93160036  1.06815915  0.68985505 -2.01150261  2.66841378\n",
      " -3.14011016  2.60618941 -1.98306322 -2.04714825  0.84736785 -3.72789722]\n",
      "AIC：\n",
      "Variable： [ True  True  True False  True  True  True False  True  True  True  True\n",
      "  True  True]\n",
      "Coefficient： [22.53280632 -0.93160036  1.06815915  0.68985505 -2.01150261  2.66841378\n",
      " -3.14011016  2.60618941 -1.98306322 -2.04714825  0.84736785 -3.72789722]\n",
      "Cross Validation：\n",
      "Variable： [ True  True  True False  True  True  True False  True  True  True  True\n",
      "  True  True]\n",
      "Coefficient： [22.53280632 -0.93160036  1.06815915  0.68985505 -2.01150261  2.66841378\n",
      " -3.14011016  2.60618941 -1.98306322 -2.04714825  0.84736785 -3.72789722]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True]),\n",
       " array([22.53280632, -0.93160036,  1.06815915,  0.68985505, -2.01150261,\n",
       "         2.66841378, -3.14011016,  2.60618941, -1.98306322, -2.04714825,\n",
       "         0.84736785, -3.72789722])]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用python自带的波士顿房价数据集\n",
    "from sklearn.datasets import load_boston\n",
    "X,y=load_boston(return_X_y=True)\n",
    "print(\"样本的个数 = {},特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X)\n",
    "X=scaler.transform(X)\n",
    "# 导入最优子集回归模型并进行训练\n",
    "model_subset = BestSubsetReg(x=X, y=y)\n",
    "# 输出子集选择结果\n",
    "model_subset.output()\n",
    "model_subset.Cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 岭回归：Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 506,特征的个数 = 13\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的波士顿房价数据集\n",
    "from sklearn.datasets import load_boston\n",
    "X,y=load_boston(return_X_y=True)\n",
    "print(\"样本的个数 = {},特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "岭回归模型拟合的均方误差为:24.77\n",
      "岭回归可以解释原变量60.464%的信息\n",
      "各变量的系数为:\n",
      " [-0.87661291  0.94946098  0.38801763  0.2961452  -1.7725836   3.10616001\n",
      " -0.01613174 -2.88171978  2.3796612  -2.05736629 -2.0040423   0.60486402\n",
      " -3.92557963]\n"
     ]
    }
   ],
   "source": [
    "# 导入岭回归函数\n",
    "from sklearn.linear_model import Ridge\n",
    "model_ridge=Ridge(alpha=0.5)  # 模型实例化\n",
    "# 模型训练及预测\n",
    "model_ridge=model_ridge.fit(X_train,y_train)\n",
    "y_pred=model_ridge.predict(X_test)\n",
    "# 模型评价：采用MSE和R^2来进行评价\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "MSE=mean_squared_error(y_pred,y_test)\n",
    "r2=r2_score(y_pred,y_test)\n",
    "print(\"岭回归模型拟合的均方误差为:{}\".format(round(MSE,3)))\n",
    "print(\"岭回归可以解释原变量%.3f%%的信息\"% (r2 *100))\n",
    "# 查看各变量的系数\n",
    "print(\"各变量的系数为:\\n\",model_ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 506,特征的个数 = 13\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的波士顿房价数据集\n",
    "from sklearn.datasets import load_boston\n",
    "X,y=load_boston(return_X_y=True)\n",
    "print(\"样本的个数 = {},特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso回归模型拟合的均方误差为:26.114\n",
      "Lasso回归可以解释原变量56.578%的信息\n",
      "各变量的系数为:\n",
      " [-0.59635319  0.61150794 -0.          0.26879248 -1.2058338   3.22791697\n",
      " -0.         -2.25261646  0.95094981 -0.80891399 -1.83453419  0.47667922\n",
      " -3.93031518]\n"
     ]
    }
   ],
   "source": [
    "# 导入Lasso回归函数\n",
    "from sklearn.linear_model import Lasso\n",
    "model_lasso=Lasso(alpha=0.1)  # 模型实例化\n",
    "# 模型训练及预测\n",
    "model_lasso=model_lasso.fit(X_train,y_train)\n",
    "y_pred=model_lasso.predict(X_test)\n",
    "# 模型评价：采用MSE和R^2来进行评价\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "MSE=mean_squared_error(y_pred,y_test)\n",
    "r2=r2_score(y_pred,y_test)\n",
    "print(\"Lasso回归模型拟合的均方误差为:{}\".format(round(MSE,3)))\n",
    "print(\"Lasso回归可以解释原变量%.3f%%的信息\"% (r2 *100))\n",
    "# 查看各变量的系数\n",
    "print(\"各变量的系数为:\\n\",model_lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 弹性网：Elastic-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 506,特征的个数 = 13\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的波士顿房价数据集\n",
    "from sklearn.datasets import load_boston\n",
    "X,y=load_boston(return_X_y=True)\n",
    "print(\"样本的个数 = {},特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic_Net模型拟合的均方误差为:31.899\n",
      "Elastic_Net可以解释原变量3.574%的信息\n",
      "各变量的系数为:\n",
      " [-0.36754177  0.04144601 -0.26162353  0.09944001 -0.19657701  2.57774603\n",
      " -0.         -0.         -0.         -0.39236921 -1.25194015  0.31277891\n",
      " -2.3950601 ]\n"
     ]
    }
   ],
   "source": [
    "# 导入弹性网函数\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model_elastic=ElasticNet()  # 模型实例化\n",
    "# 模型训练及预测\n",
    "model_elastic=model_elastic.fit(X_train,y_train)\n",
    "y_pred=model_elastic.predict(X_test)\n",
    "# 模型评价：采用MSE和R^2来进行评价\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "MSE=mean_squared_error(y_pred,y_test)\n",
    "r2=r2_score(y_pred,y_test)\n",
    "print(\"Elastic_Net模型拟合的均方误差为:{}\".format(round(MSE,3)))\n",
    "print(\"Elastic_Net可以解释原变量%.3f%%的信息\"% (r2 *100))\n",
    "# 查看各变量的系数\n",
    "print(\"各变量的系数为:\\n\",model_elastic.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自适应Lasso：Adaptive Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adaptive_LASSO(X_train,y_train,max_iterations = 1000,lasso_iterations = 10, alpha = 0.1, tol = 0.001, max_error_up = 5, title = ''):\n",
    "    \n",
    "    from sklearn.linear_model import Lasso\n",
    "    # set checks\n",
    "    higher  = float('inf')\n",
    "    lower   = 0\n",
    "    \n",
    "    # set lists\n",
    "    coefficients_list = []\n",
    "    iterations_list   = []\n",
    "    \n",
    "    # set variables\n",
    "    X_train  = X_train\n",
    "    y_train  = y_train\n",
    "    \n",
    "    # set constants\n",
    "    alpha    = alpha\n",
    "    tol      = tol\n",
    "    max_iter = max_iterations\n",
    "    n_lasso_iterations = lasso_iterations\n",
    "    \n",
    "    g = lambda w: np.sqrt(np.abs(w))\n",
    "    gprime = lambda w: 1. / (2. * np.sqrt(np.abs(w)) + np.finfo(float).eps)\n",
    "\n",
    "    n_samples, n_features = X_train.shape\n",
    "    p_obj = lambda w: 1. / (2 * n_samples) * np.sum((y_train - np.dot(X_train, w)) ** 2) \\\n",
    "                      + alpha * np.sum(g(w))\n",
    "\n",
    "    weights = np.ones(n_features)\n",
    "\n",
    "    X_w = X_train / weights[np.newaxis, :]\n",
    "    X_w  = np.nan_to_num(X_w)\n",
    "    X_w  = np.round(X_w,decimals = 3)\n",
    "\n",
    "    y_train    = np.nan_to_num(y_train)\n",
    "\n",
    "    adaptive_lasso = Lasso(alpha=alpha, fit_intercept=False)\n",
    "\n",
    "    adaptive_lasso.fit(X_w, y_train)\n",
    "\n",
    "    for k in range(n_lasso_iterations):\n",
    "        X_w = X_train / weights[np.newaxis, :]\n",
    "        adaptive_lasso = Lasso(alpha=alpha, fit_intercept=False)\n",
    "        adaptive_lasso.fit(X_w, y_train)\n",
    "        coef_ = adaptive_lasso.coef_ / weights\n",
    "        weights = gprime(coef_)\n",
    "        \n",
    "        print ('Iteration #',k+1,':   ',p_obj(coef_))  # should go down\n",
    "        \n",
    "        iterations_list.append(k)\n",
    "        coefficients_list.append(p_obj(coef_))\n",
    "        \n",
    "    print (np.mean((adaptive_lasso.coef_ != 0.0) == (coef_ != 0.0)))   \n",
    "    \n",
    "    coef = pd.Series(adaptive_lasso.coef_, index = X_train.columns)\n",
    "    print('=============================================================================')\n",
    "    print(\"Adaptive LASSO picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables.\")\n",
    "    print('=============================================================================')\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "    plt.figure()\n",
    "    # subplot of the predicted vs. actual\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(iterations_list,coefficients_list,color = 'orange')\n",
    "    plt.scatter(iterations_list,coefficients_list,color = 'green')\n",
    "    plt.title('Iterations vs. p_obj(coef_)')\n",
    "\n",
    "    # plot of the coefficients'\n",
    "    plt.subplot(1,2,2)\n",
    "    imp_coef = pd.concat([coef.sort_values().head(10),coef.sort_values().tail(10)])\n",
    "    imp_coef.plot(kind = \"barh\", color = 'green',  fontsize=14)\n",
    "    plt.title(\"Coefficients Selected by the Adaptive LASSO Model\", fontsize = 14)\n",
    "    plt.show()\n",
    "    return adaptive_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 1 :    264.20608057659007\n",
      "Iteration # 2 :    264.1454183301053\n",
      "Iteration # 3 :    264.1434144508424\n",
      "Iteration # 4 :    264.14335384316723\n",
      "Iteration # 5 :    264.1433519584512\n",
      "Iteration # 6 :    264.1433519061564\n",
      "Iteration # 7 :    264.14335190824914\n",
      "Iteration # 8 :    264.14335190925414\n",
      "1.0\n",
      "=============================================================================\n",
      "Adaptive LASSO picked 11 variables and eliminated the other 2 variables.\n",
      "=============================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train=pd.DataFrame(X_train)\n",
    "model_lasso=Adaptive_LASSO(X_train,y_train,lasso_iterations=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable selection with LASSO for the model\n",
    "\n",
    "#y_train = numbers_df['y']\n",
    "#X_train = numbers_df[[col for col in numbers_df.columns if col != 'y']]\n",
    "\n",
    "#model = Adaptive_LASSO(X_train,\n",
    "#                       y_train,\n",
    "#                       max_iterations = 1000,\n",
    "#                       lasso_iterations = 10, \n",
    "#                       alpha = 0.1, \n",
    "#                       tol = 0.001, \n",
    "#                       max_error_up = 5, \n",
    "#                       title = '')\n",
    "\n",
    "# look at the coefficients in the model\n",
    "\n",
    "#coef = pd.Series(model.coef_, index = X_train.columns)\n",
    "#coef = pd.DataFrame(coef).reset_index()\n",
    "#coef_list = coef.loc[coef[0]!= 0.0]['index'].to_list()\n",
    "#new_X_train = X_train[coef_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析：PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(load_breast_cancer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_breast_cancer().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569,     变量的个数 = 30\n",
      "1 个主成分可以解释原变量44.272%的信息\n",
      "2 个主成分可以解释原变量63.243%的信息\n",
      "3 个主成分可以解释原变量72.636%的信息\n",
      "4 个主成分可以解释原变量79.239%的信息\n",
      "5 个主成分可以解释原变量84.734%的信息\n",
      "6 个主成分可以解释原变量88.759%的信息\n",
      "7 个主成分可以解释原变量91.010%的信息\n",
      "8 个主成分可以解释原变量92.598%的信息\n",
      "9 个主成分可以解释原变量93.988%的信息\n",
      "10 个主成分可以解释原变量95.157%的信息\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {},     变量的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 将特征数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X)\n",
    "X=scaler.transform(X)\n",
    "# 导入PCA函数\n",
    "from sklearn.decomposition import PCA\n",
    "# 进行主成分降维，并比较在不同主成分个数的情况下的方差累计贡献率\n",
    "for i in range(1,11):\n",
    "    pca=PCA(n_components=i)\n",
    "    pca.fit(X)\n",
    "    variance_ratio=pca.explained_variance_ratio_\n",
    "    print(i,\"个主成分可以解释原变量%.3f%%的信息\"% (np.sum(variance_ratio) *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "ID3决策树模型拟合的准确率为:97.203%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 导入决策树函数,criterion设为信息增益\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model18=DecisionTreeClassifier(criterion='entropy')\n",
    "# 模型训练及预测\n",
    "model18=model18.fit(X_train,y_train)\n",
    "y_pred=model18.predict(X_test)\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"ID3决策树模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "CART决策树模型拟合的准确率为:97.203%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 导入决策树函数,criterion设为基尼系数\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model20=DecisionTreeClassifier(criterion='gini')\n",
    "# 模型训练及预测\n",
    "model20=model20.fit(X_train,y_train)\n",
    "y_pred=model20.predict(X_test)\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"CART决策树模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RRuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-36363ade72f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpackages\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimportr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimportr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rpart'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimportr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rpart.plot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\kw\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\packages.py\u001b[0m in \u001b[0;36mimportr\u001b[1;34m(name, lib_loc, robject_translations, signature_translation, suppress_messages, on_conflict, symbol_r2python, symbol_check_after, data)\u001b[0m\n\u001b[0;32m    451\u001b[0m     if _package_has_namespace(rname, \n\u001b[0;32m    452\u001b[0m                               _system_file(package = rname)):\n\u001b[1;32m--> 453\u001b[1;33m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_namespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m         \u001b[0mversion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_namespace_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[0mexported_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_namespace_exports\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from rpy2.robjects import r\n",
    "from rpy2.robjects.packages import importr\n",
    "importr('rpart')\n",
    "importr('rpart.plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RRuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-042ebf5019fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#importr('rpart.plot')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'install.packages'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rpart.plot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\kw\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\functions.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr_k\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSignatureTranslatedFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[0mpattern_link\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\link\\{(.+?)\\}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\kw\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\functions.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mnew_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy2ri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mri2ro\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#importr('rpart.plot')\n",
    "r['install.packages']('rpart.plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 通过python程序调用R自带的iris数据集\n",
    "data_sample=\"\"\"\n",
    "#使用R自带的iris数据集\n",
    "data=iris\n",
    "head(iris)\n",
    "# 通过留出法划分数据集\n",
    "set.seed(123)\n",
    "train_index=sample(nrow(data),0.7*nrow(data))\n",
    "train_data=data[train_index,]\n",
    "test_data=data[-train_index,]\n",
    "\"\"\"\n",
    "# 通过调用rpy2包，用python执行R程序\n",
    "r(data_sample)\n",
    "# 将y_true 数据格式转化为np.array\n",
    "y_true=np.array(r(\"test_data$Species\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3决策树未剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'importr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d861ab89e52c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 导入ID3决策树需要的函数包\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rpart'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimportr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rpart.plot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m ID3_tree=\"\"\"\n\u001b[0;32m      5\u001b[0m ID3_tree=rpart(train_data$Species~.,data=train_data,method=\"class\",\n",
      "\u001b[1;31mNameError\u001b[0m: name 'importr' is not defined"
     ]
    }
   ],
   "source": [
    "# 导入ID3决策树需要的函数包\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects.packages import importr\n",
    "importr('rpart')\n",
    "importr('rpart.plot')\n",
    "ID3_tree=\"\"\"\n",
    "ID3_tree=rpart(train_data$Species~.,data=train_data,method=\"class\",\n",
    "               parms=list(split=\"information\"),minsplit=0)\n",
    "rpart.plot(ID3_tree,branch=1,type=2, fallen.leaves=T,cex=0.8, sub=\"ID3—未剪枝\")\n",
    "pred_ID3_tree=predict(ID3_tree,test_data,type='class')\n",
    "\"\"\"\n",
    "# 通过python执行R中的ID3决策树程序\n",
    "r(ID3_tree)\n",
    "# 导出ID3决策树（未剪枝）的预测值，并转换为np.array格式\n",
    "y_pred_ID3=np.array(r(\"pred_ID3_tree\"))\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_ID3,y_true))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred_ID3,y_true)\n",
    "print(\"ID3决策树（未剪枝）拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3决策树（预剪枝）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      0.95      0.97        19\n",
      "           3       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "ID3决策树（预剪枝）拟合的准确率为:97.778%\n"
     ]
    }
   ],
   "source": [
    "# 导入ID3决策树需要的函数包\n",
    "importr('rpart')\n",
    "importr('rpart.plot')\n",
    "ID3_tree_pre=\"\"\"\n",
    " # 将每个叶节点最小样本数设为20\n",
    "ID3_tree_pre=rpart(train_data$Species~.,data=train_data,method=\"class\",\n",
    "               parms=list(split=\"information\"),minsplit=20)\n",
    "rpart.plot(ID3_tree_pre,branch=1,type=2, fallen.leaves=T,cex=0.8, sub=\"ID3—预剪枝\")\n",
    "pred_ID3_tree_pre=predict(ID3_tree_pre,test_data,type='class')\n",
    "\"\"\"\n",
    "# 通过python执行R中的ID3决策树程序\n",
    "r(ID3_tree_pre)\n",
    "# 导出ID3决策树（预剪枝）的预测值，并转换为np.array格式\n",
    "y_pred_ID3_pre=np.array(r(\"pred_ID3_tree_pre\"))\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_ID3_pre,y_true))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred_ID3_pre,y_true)\n",
    "print(\"ID3决策树（预剪枝）拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3决策树（后剪枝）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      0.95      0.97        19\n",
      "           3       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "ID3决策树（后剪枝）拟合的准确率为:97.778%\n"
     ]
    }
   ],
   "source": [
    "# 导入ID3决策树需要的函数包\n",
    "importr('rpart')\n",
    "importr('rpart.plot')\n",
    "ID3_tree_after=\"\"\"\n",
    "#后剪枝，将CP值设为0.1\n",
    "ID3_tree_after<-prune(ID3_tree,cp=0.1)\n",
    "rpart.plot(ID3_tree_after,branch=1,type=2, fallen.leaves=T,cex=0.8, sub=\"ID3—后剪枝\")\n",
    "pred_ID3_tree_after=predict(ID3_tree_after,test_data,type='class')\n",
    "\"\"\"\n",
    "# 通过python执行R中的ID3决策树程序\n",
    "r(ID3_tree_after)\n",
    "# 导出ID3决策树（后剪枝）的预测值，并转换为np.array格式\n",
    "y_pred_ID3_after=np.array(r(\"pred_ID3_tree_after\"))\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_ID3_after,y_true))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred_ID3_after,y_true)\n",
    "print(\"ID3决策树（后剪枝）拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4.5决策树：未剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       0.94      1.00      0.97        17\n",
      "           3       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "C4.5决策树（未剪枝）拟合的准确率为:97.778%\n"
     ]
    }
   ],
   "source": [
    "# 导入C4.5决策树需要的函数包\n",
    "importr('RWeka')\n",
    "importr('partykit')\n",
    "C4_5_tree=\"\"\"\n",
    " # 将每个叶节点最小样本数设为20\n",
    "C4_5_tree=J48(factor(train_data$Species)~.,data=train_data,control=Weka_control(M=2))\n",
    "plot(C4_5_tree,main=\"C4.5—未剪枝\")\n",
    "pred_C4_5_tree=predict(C4_5_tree,test_data,type='class')\n",
    "\"\"\"\n",
    "# 通过python执行R中的C4.5决策树程序\n",
    "r(C4_5_tree)\n",
    "# 导出C4.5决策树（未剪枝）的预测值，并转换为np.array格式\n",
    "y_pred_C4_5=np.array(r(\"pred_C4_5_tree\"))\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_C4_5,y_true))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred_C4_5,y_true)\n",
    "print(\"C4.5决策树（未剪枝）拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4.5决策树：预剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       0.89      0.94      0.91        17\n",
      "           3       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n",
      "C4.5决策树（预剪枝）拟合的准确率为:93.333%\n"
     ]
    }
   ],
   "source": [
    "# 导入C4.5决策树需要的函数包\n",
    "importr('RWeka')\n",
    "importr('partykit')\n",
    "C4_5_tree_pre=\"\"\"\n",
    "#预剪枝\n",
    "C4_5_tree_pre=J48(factor(train_data$Species)~.,data=train_data,\n",
    "                  control=Weka_control(U=T,M=5))\n",
    "plot(C4_5_tree_pre,main=\"C4.5—预剪枝\")\n",
    "pred_C4_5_tree_pre=predict(C4_5_tree_pre,test_data,type='class')\n",
    "\"\"\"\n",
    "# 通过python执行R中的C4.5决策树程序\n",
    "r(C4_5_tree_pre)\n",
    "# 导出C4.5决策树（预剪枝）的预测值，并转换为np.array格式\n",
    "y_pred_C4_5_pre=np.array(r(\"pred_C4_5_tree_pre\"))\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_C4_5_pre,y_true))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred_C4_5_pre,y_true)\n",
    "print(\"C4.5决策树（预剪枝）拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART决策树：未剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       0.89      1.00      0.94        16\n",
      "           3       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "CART决策树（未剪枝）拟合的准确率为:95.556%\n"
     ]
    }
   ],
   "source": [
    "# 导入CART决策树需要的函数包\n",
    "importr('rpart')\n",
    "importr('rpart.plot')\n",
    "CART_tree=\"\"\"\n",
    "CART_tree=rpart(train_data$Species~.,data=train_data,method=\"class\",\n",
    "               parms=list(split=\"gini\"),minsplit=0)\n",
    "rpart.plot(CART_tree,branch=1,type=2, fallen.leaves=T,cex=0.8, sub=\"CART—未剪枝\")\n",
    "pred_CART_tree=predict(CART_tree,test_data,type='class')\n",
    "\"\"\"\n",
    "# 通过python执行R中的CART决策树程序\n",
    "r(CART_tree)\n",
    "# 导出CART决策树（未剪枝）的预测值，并转换为np.array格式\n",
    "y_pred_CART=np.array(r(\"pred_CART_tree\"))\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_CART,y_true))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred_CART,y_true)\n",
    "print(\"CART决策树（未剪枝）拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART决策树：预剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      0.95      0.97        19\n",
      "           3       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "CART决策树（预剪枝）拟合的准确率为:97.778%\n"
     ]
    }
   ],
   "source": [
    "# 导入CART决策树需要的函数包\n",
    "importr('rpart')\n",
    "importr('rpart.plot')\n",
    "CART_tree_pre=\"\"\"\n",
    "#将每个叶节点最小样本数设为20\n",
    "CART_tree_pre=rpart(train_data$Species~.,data=train_data,method=\"class\",\n",
    "               parms=list(split=\"gini\"),minsplit=20)\n",
    "rpart.plot(CART_tree_pre,branch=1,type=2, fallen.leaves=T,cex=0.8, sub=\"CART—预剪枝\")\n",
    "pred_CART_tree_pre=predict(CART_tree_pre,test_data,type='class')\n",
    "\"\"\"\n",
    "# 通过python执行R中的CART决策树程序\n",
    "r(CART_tree_pre)\n",
    "# 导出CART决策树（预剪枝）的预测值，并转换为np.array格式\n",
    "y_pred_CART_pre=np.array(r(\"pred_CART_tree_pre\"))\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_CART_pre,y_true))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred_CART_pre,y_true)\n",
    "print(\"CART决策树（预剪枝）拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART决策树：后剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      0.95      0.97        19\n",
      "           3       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "CART决策树（后剪枝）拟合的准确率为:97.778%\n"
     ]
    }
   ],
   "source": [
    "# 导入CART决策树需要的函数包\n",
    "importr('rpart')\n",
    "importr('rpart.plot')\n",
    "CART_tree_after=\"\"\"\n",
    "#后剪枝，将CP值设为0.1\n",
    "CART_tree_after<-prune(CART_tree,cp=0.1)\n",
    "rpart.plot(CART_tree_after,branch=1,type=2, fallen.leaves=T,cex=0.8, sub=\"CART—后剪枝\")\n",
    "pred_CART_tree_after=predict(CART_tree_after,test_data,type='class')\n",
    "\"\"\"\n",
    "# 通过python执行R中的CART决策树程序\n",
    "r(CART_tree_after)\n",
    "# 导出CART决策树（后剪枝）的预测值，并转换为np.array格式\n",
    "y_pred_CART_after=np.array(r(\"pred_CART_tree_after\"))\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_CART_after,y_true))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred_CART_after,y_true)\n",
    "print(\"CART决策树（后剪枝）拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C5.0决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       0.94      1.00      0.97        17\n",
      "           3       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "C5.0决策树拟合的准确率为:97.778%\n"
     ]
    }
   ],
   "source": [
    "# 导入C5.0决策树需要的函数包\n",
    "importr('C50')\n",
    "C50_tree=\"\"\"\n",
    "C50_tree=C5.0(x=train_data[,-5],y=factor(train_data$Species))\n",
    "plot(C50_tree,main=\"C5.0决策树\")\n",
    "pred_C50_tree=predict(C50_tree,test_data,type='class')\n",
    "\"\"\"\n",
    "# 通过python执行R中的C5.0决策树程序\n",
    "r(C50_tree)\n",
    "# 导出C5.0决策树的预测值，并转换为np.array格式\n",
    "y_pred_C50=np.array(r(\"pred_C50_tree\"))\n",
    "# 模型评价\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_C50,y_true))\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred_C50,y_true)\n",
    "print(\"C5.0决策树拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 支持向量机：SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性支持向量机模型拟合的准确率为:98.601%\n"
     ]
    }
   ],
   "source": [
    "# 导入支持向量机函数：核函数为线性核\n",
    "from sklearn.svm import SVC\n",
    "model12=SVC(kernel='linear')\n",
    "# 模型训练及预测\n",
    "model12=model12.fit(X_train,y_train)\n",
    "y_pred=model12.predict(X_test)\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"线性支持向量机模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核支持向量机（RBF核）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF核支持向量机模型拟合的准确率为:98.601%\n"
     ]
    }
   ],
   "source": [
    "# 导入支持向量机函数：核函数为RBF核\n",
    "from sklearn.svm import SVC\n",
    "model13=SVC(kernel='rbf')\n",
    "# 模型训练及预测\n",
    "model13=model13.fit(X_train,y_train)\n",
    "y_pred=model13.predict(X_test)\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"RBF核支持向量机模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 导入定义神经网络所需的函数\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "# 自定义三层神经网络模型\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=30,activation=\"relu\"),\n",
    "    Dense(32,activation=\"relu\"),\n",
    "    Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "print(model.summary())\n",
    "# 模型编译\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# 模型训练及评价\n",
    "model.fit(X_train, y_train,epochs=500,batch_size=32,verbose=0)\n",
    "loss,Acc= model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(\"BP神经网络模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "# 自定义RBF激活函数\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mu = self.add_weight(name='mu',\n",
    "                                  shape=(int(input_shape[1]), self.units),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = K.expand_dims(inputs) - self.mu\n",
    "        l2 = K.sum(K.pow(diff,2), axis=1)\n",
    "        res = K.exp(-1 * self.gamma * l2)\n",
    "        return res\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "rbf_layer_4 (RBFLayer)       (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "143/143 [==============================] - 0s 480us/step\n",
      "RBF神经网络模型拟合的准确率为:99.301%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 自定义二层RBF神经网络\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(30,)))\n",
    "model.add(RBFLayer(16,0.5))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "print(model.summary())\n",
    "# 模型编译\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# 模型训练及评价\n",
    "model.fit(X_train, y_train,epochs=500,batch_size=32,verbose=0)\n",
    "loss,Acc= model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(\"RBF神经网络模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import *\n",
    "from scipy.linalg import norm, pinv\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import exp\n",
    "\n",
    "class RBF(object):\n",
    "     \n",
    "    def __init__(self, indim, nhiddens, outdim):\n",
    "        self.indim = indim\n",
    "        self.outdim = outdim\n",
    "        self.nhiddens = nhiddens\n",
    "        self.centers = [random.uniform(-1, 1, indim) for i in range(nhiddens)]\n",
    "        self.beta = 8\n",
    "        self.W = random.random((self.nhiddens, self.outdim))\n",
    "         \n",
    "    def _basisfunc(self, c, d):\n",
    "        assert len(d) == self.indim\n",
    "        return exp(-self.beta * norm(c-d)**2)\n",
    "     \n",
    "    def _calcAct(self, X):\n",
    "        # calculate activations of RBFs\n",
    "        G = zeros((X.shape[0], self.nhiddens), float)\n",
    "        for ci, c in enumerate(self.centers):\n",
    "            for xi, x in enumerate(X):\n",
    "                G[xi,ci] = self._basisfunc(c, x)\n",
    "        return G\n",
    "     \n",
    "    def train(self, X, Y):\n",
    "        \"\"\" X: matrix of dimensions n x indim \n",
    "            y: column vector of dimension n x 1 \"\"\"\n",
    "         \n",
    "        # choose random center vectors from training set\n",
    "        random.seed(10)\n",
    "#        rnd_idx = random.permutation(X.shape[0])[:self.numCenters]\n",
    "#        self.centers = [X[i,:] for i in rnd_idx]\n",
    "        self.centers = X[random.choice(X.shape[0],self.nhiddens)]\n",
    "        \n",
    "#        print (\"center\", self.centers)\n",
    "        # calculate activations of RBFs\n",
    "        G = self._calcAct(X)\n",
    "#        print ('G \\n',G)\n",
    "         \n",
    "        # calculate output weights (pseudoinverse)\n",
    "        self.W = dot(pinv(G), Y)\n",
    "        return self.centers, G \n",
    "         \n",
    "    def test(self, X):\n",
    "        \"\"\" X: matrix of dimensions n x indim \"\"\"\n",
    "         \n",
    "        G = self._calcAct(X)\n",
    "        Y = dot(G, self.W)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "if __name__ == '__main__':\n",
    "    # rbf regression\n",
    "    rbf = RBF(1, 10, 1)\n",
    "    center, G = rbf.train(x, y)\n",
    "    z = rbf.test(x)\n",
    "       \n",
    "    # plot original data\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(x, y, 'k-')\n",
    "     \n",
    "    # plot learned model\n",
    "    plt.plot(x, z, 'r-', linewidth=2)\n",
    "#     \n",
    "    # plot rbfs\n",
    "    plt.plot(rbf.centers, zeros(rbf.numCenters), 'gs')\n",
    "     \n",
    "    for c in rbf.centers:\n",
    "        # RF prediction lines\n",
    "        cx = arange(c-0.7, c+0.7, 0.01)\n",
    "        cy = [rbf._basisfunc(array([cx_]), array([c])) for cx_ in cx]\n",
    "        plt.plot(cx, cy, '-', color='gray', linewidth=0.2)\n",
    "     \n",
    "    plt.xlim(-1.2, 1.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: scipy.zeros is deprecated and will be removed in SciPy 2.0.0, use numpy.zeros instead\n",
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: DeprecationWarning: scipy.dot is deprecated and will be removed in SciPy 2.0.0, use numpy.dot instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: DeprecationWarning: scipy.dot is deprecated and will be removed in SciPy 2.0.0, use numpy.dot instead\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 导入RBF神经网络模型\n",
    "model_rbf=RBF(30,15,1)\n",
    "center,G=model_rbf.train(X_train,y_train)\n",
    "y_pred=model_rbf.test(X_train)\n",
    "print(y_pred.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.initializers import RandomUniform, Initializer, Constant\n",
    "import numpy as np\n",
    "\n",
    "class InitCentersRandom(Initializer):\n",
    "    \"\"\" Initializer for initialization of centers of RBF network\n",
    "        as random samples from the given data set.\n",
    "    # Arguments\n",
    "        X: matrix, dataset to choose the centers from (random rows\n",
    "          are taken as centers)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        assert shape[1] == self.X.shape[1]\n",
    "        idx = np.random.randint(self.X.shape[0], size=shape[0])\n",
    "        return self.X[idx, :]\n",
    "\n",
    "\n",
    "class RBFLayer(Layer):\n",
    "    \"\"\" Layer of Gaussian RBF units.\n",
    "    # Arguments\n",
    "        output_dim: number of hidden units (i.e. number of outputs of the\n",
    "                    layer)\n",
    "        initializer: instance of initiliazer to initialize centers\n",
    "        betas: float, initial value for betas\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_dim, initializer=None, betas=1.0, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.init_betas = betas\n",
    "        if not initializer:\n",
    "            self.initializer = RandomUniform(0.0, 1.0)\n",
    "        else:\n",
    "            self.initializer = initializer\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.centers = self.add_weight(name='centers',\n",
    "                                       shape=(self.output_dim, input_shape[1]),\n",
    "                                       initializer=self.initializer,\n",
    "                                       trainable=True)\n",
    "        self.betas = self.add_weight(name='betas',\n",
    "                                     shape=(self.output_dim,),\n",
    "                                     initializer=Constant(\n",
    "                                         value=self.init_betas),\n",
    "                                     # initializer='ones',\n",
    "                                     trainable=True)\n",
    "\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        C = K.expand_dims(self.centers)\n",
    "        H = K.transpose(C-K.transpose(x))\n",
    "        return K.exp(-self.betas * K.sum(H**2, axis=1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        # have to define get_config to be able to use model_from_json\n",
    "        config = {\n",
    "            'output_dim': self.output_dim\n",
    "        }\n",
    "        base_config = super(RBFLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rbf_layer_22 (RBFLayer)      (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 321\n",
      "Trainable params: 321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "model=Sequential()\n",
    "model.add(RBFLayer(10,betas=8.0,input_shape=(30,),initializer=InitCentersRandom(X_train)))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "print(model.summary())\n",
    "# 模型编译\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# 模型训练及评价\n",
    "model.fit(X_train, y_train,epochs=200,batch_size=32,verbose=0)\n",
    "y_pred=model.predict(X_test)\n",
    "#loss,Acc= model.evaluate(X_test, y_test, batch_size=32)\n",
    "#print(\"BP神经网络模型拟合的准确率为:%.3f%%\"% (Acc *100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 自定义广义回归神经网络模型（GRNN）\n",
    "class GRNN(object):\n",
    "    def __init__(self,X_train,y_train,X_test,y_test):\n",
    "        self.x_train= X_train\n",
    "        self.y_train= y_train\n",
    "        self.x_test= X_test\n",
    "        self.y_test= y_test\n",
    "        #np.random.rand(1,self.train_y.size) #Standard deviations(std) are sometimes called RBF widths.\n",
    "        self.std = np.ones((1,self.y_train.size))\n",
    "        \n",
    "    def activation_func(self,distances): # gaussian kernel        \n",
    "        return np.exp(- (distances**2) / 2*(self.std**2) )\n",
    "\n",
    "    def output(self,i):#sometimes called weight\n",
    "        distances=np.sqrt(np.sum((self.x_test[i]-self.x_train)**2,axis=1)) # euclidean distance        \n",
    "        return self.activation_func(distances)\n",
    "   \n",
    "    def denominator(self,i):\n",
    "        return np.sum(self.output(i))\n",
    "\n",
    "    def numerator(self,i): \n",
    "        return  np.sum(self.output(i) * self.y_train)\n",
    "    \n",
    "    def predict(self):\n",
    "        predict_array = np.array([])\n",
    "        for i in range(self.y_test.size):\n",
    "            predict=np.array([self.numerator(i)/self.denominator(i)])\n",
    "            predict_array=np.append(predict_array,predict)        \n",
    "        return predict_array\n",
    "    \n",
    "    def squared_error(self):\n",
    "        return (self.predict()-self.y_test)**2 \n",
    "    \n",
    "    def root_squared_error(self):\n",
    "        return np.sqrt(self.squared_error())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 506,特征的个数 = 13\n",
      "GRNN模型拟合的均方误差为:23.402\n",
      "GRNN模型自定义的MSE为:23.402\n",
      "GRNN可以解释原变量53.297%的信息\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的波士顿房价数据集\n",
    "from sklearn.datasets import load_boston\n",
    "X,y=load_boston(return_X_y=True)\n",
    "print(\"样本的个数 = {},特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 导入自定义的GRNN，并进行训练和预测\n",
    "model_grnn=GRNN(X_train,y_train,X_test,y_test)\n",
    "y_pred=model_grnn.predict()\n",
    "# 模型评价\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "MSE=mean_squared_error(y_pred,y_test)\n",
    "r2=r2_score(y_pred,y_test)\n",
    "print(\"GRNN模型拟合的均方误差为:{}\".format(round(MSE,3)))\n",
    "print(\"GRNN模型自定义的MSE为:%.3f\"%(np.mean(model_grnn.squared_error())))\n",
    "print(\"GRNN可以解释原变量%.3f%%的信息\"% (r2 *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聚类分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 150, 特征的个数 = 4\n",
      "特征描述：['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "K-Means同质性得分为:0.751\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 使用python自带的鸢尾花数据集（三分类）\n",
    "from sklearn.datasets import load_iris\n",
    "X,y=load_iris(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "print(\"特征描述：{}\".format(load_iris().feature_names))\n",
    "# 画出sepal、petal length特征的分布图\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X[:,0],X[:,2],c=y)\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('petal length')\n",
    "plt.title('original_data distribution')\n",
    "# 进行K-Means聚类分析\n",
    "from sklearn.cluster import KMeans\n",
    "model_kmeans=KMeans(n_clusters=3)\n",
    "model_kmeans=model_kmeans.fit(X)\n",
    "y_kmeans=model_kmeans.labels_\n",
    "# 聚类结果评价：同质性得分\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "score=homogeneity_score(y,y_kmeans)\n",
    "print(\"K-Means同质性得分为:{}\".format(round(score,3)))\n",
    "# 画出聚类后的结果\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X[:,0],X[:,2],c=y_kmeans)\n",
    "centers=model_kmeans.cluster_centers_\n",
    "plt.scatter(centers[:,0],centers[:,2],c=\"red\",s=200,alpha=0.5,label=\"cluster center\")\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('petal length')\n",
    "plt.title('The result of K-Means')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 系统聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "# 定义谱系图\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 150, 特征的个数 = 4\n",
      "特征描述：['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "系统聚类同质性得分为:1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 使用python自带的鸢尾花数据集（三分类）\n",
    "from sklearn.datasets import load_iris\n",
    "X,y=load_iris(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "print(\"特征描述：{}\".format(load_iris().feature_names))\n",
    "# 导入系统聚类模型并训练\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "model_Aggcluster = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "model_Aggcluster= model_Aggcluster.fit(X)\n",
    "y_aggcluster=model_Aggcluster.labels_\n",
    "# 聚类结果评价：同质性得分\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "score=homogeneity_score(y,y_aggcluster)\n",
    "print(\"系统聚类同质性得分为:{}\".format(round(score,3)))\n",
    "# 根据聚类结果画出谱系图\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plot_dendrogram(model_Aggcluster, truncate_mode='level', p=3)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 密度聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 150, 特征的个数 = 4\n",
      "特征描述：['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Estimated number of clusters: 2\n",
      "Estimated number of noise points: 13\n",
      "K-Means同质性得分为:0.563\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 使用python自带的鸢尾花数据集（三分类）\n",
    "from sklearn.datasets import load_iris\n",
    "X,y=load_iris(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "print(\"特征描述：{}\".format(load_iris().feature_names))\n",
    "# 画出sepal、petal length特征的分布图\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X[:,0],X[:,2],c=y)\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('petal length')\n",
    "plt.title('original_data distribution')\n",
    "# 进行K-Means聚类分析\n",
    "from sklearn.cluster import DBSCAN\n",
    "model_dbscan=DBSCAN(eps=0.6, min_samples=10).fit(X)\n",
    "y_dbscan=model_dbscan.labels_\n",
    "core_samples_mask = np.zeros_like(y_dbscan, dtype=bool)\n",
    "core_samples_mask[model_dbscan.core_sample_indices_] = True\n",
    "n_clusters_ = len(set(y_dbscan)) - (1 if -1 in y_dbscan else 0)\n",
    "n_noise_ = list(y_dbscan).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "# 聚类结果评价：同质性得分\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "score=homogeneity_score(y,y_dbscan)\n",
    "print(\"K-Means同质性得分为:{}\".format(round(score,3)))\n",
    "# 画出聚类后的结果\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X[:,0],X[:,2],c=y_dbscan)\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('petal length')\n",
    "plt.title('The result of DBSCAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集成学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林：Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "随机森林模型拟合的准确率为:99.301%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 导入随机森林函数,使用二十棵决策树进行集成\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model13=RandomForestClassifier(n_estimators=20)\n",
    "# 模型训练及预测\n",
    "model13=model13.fit(X_train,y_train)\n",
    "y_pred=model13.predict(X_test)\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"随机森林模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "Bagging模型拟合的准确率为:98.601%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 导入BaggingClassifier函数,使用20棵决策树作为基分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "model17=BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=20)\n",
    "# 模型训练及预测\n",
    "model17=model17.fit(X_train,y_train)\n",
    "y_pred=model17.predict(X_test)\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"Bagging模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "AdaBoost模型拟合的准确率为:96.503%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 导入AdaBoost函数,使用20棵决策树\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model14=AdaBoostClassifier(n_estimators=20)\n",
    "# 模型训练及预测\n",
    "model14=model14.fit(X_train,y_train)\n",
    "y_pred=model14.predict(X_test)\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"AdaBoost模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n",
      "GBDT模型拟合的准确率为:97.902%\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 导入GBDT函数：使用20棵决策树\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model15=GradientBoostingClassifier(n_estimators=20)\n",
    "# 模型训练及预测\n",
    "model15=model15.fit(X_train,y_train)\n",
    "y_pred=model15.predict(X_test)\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"GBDT模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优点\n",
    "1. 精度更高：GBDT 只用到一阶泰勒展开，而 XGBoost 对损失函数进行了二阶泰勒展开。XGBoost 引入二阶导一方面是为了增加精度，另一方面也是为了能够自定义损失函数，二阶泰勒展开可以近似大量损失函数；\n",
    "2. 灵活性更强：GBDT 以 CART 作为基分类器，XGBoost 不仅支持 CART 还支持线性分类器，使用线性分类器的 XGBoost 相当于带 和 正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。此外，XGBoost 工具支持自定义损失函数，只需函数支持一阶和二阶求导；\n",
    "3. 正则化：XGBoost 在目标函数中加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、叶子节点权重的 范式。正则项降低了模型的方差，使学习出来的模型更加简单，有助于防止过拟合，这也是XGBoost优于传统GBDT的一个特性。\n",
    "4. Shrinkage（缩减）：相当于学习速率。XGBoost 在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。传统GBDT的实现也有学习速率；\n",
    "5. 列抽样：XGBoost 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算。这也是XGBoost异于传统GBDT的一个特性；\n",
    "6. 缺失值处理：对于特征的值有缺失的样本，XGBoost 采用的稀疏感知算法可以自动学习出它的分裂方向；\n",
    "7. XGBoost工具支持并行：boosting不是一种串行的结构吗?怎么并行的？注意XGBoost的并行不是tree粒度的并行，XGBoost也是一次迭代完才能进行下一次迭代的（第次迭代的代价函数里包含了前面次迭代的预测值）。XGBoost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），XGBoost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。\n",
    "8. 可并行的近似算法：树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以XGBoost还提出了一种可并行的近似算法，用于高效地生成候选的分割点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺点\n",
    "1. 虽然利用预排序和近似算法可以降低寻找最佳分裂点的计算量，但在节点分裂过程中仍需要遍历数据集；\n",
    "2. 预排序过程的空间复杂度过高，不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本的个数 = 569, 特征的个数 = 30\n"
     ]
    }
   ],
   "source": [
    "# 使用python自带的乳腺癌数据集（二分类）\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "print(\"样本的个数 = {}, 特征的个数 = {}\".format(X.shape[0],X.shape[1]))\n",
    "# 采用留出法划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "# 将数据进行标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.02113\n",
      "[1]\ttrain-error:0.02113\n",
      "[2]\ttrain-error:0.02113\n",
      "[3]\ttrain-error:0.02113\n",
      "[4]\ttrain-error:0.02113\n",
      "XGBoost模型拟合的准确率为:97.902%\n"
     ]
    }
   ],
   "source": [
    "# 导入xgboost模型，并设置参数\n",
    "import xgboost as xgb\n",
    "data_train=xgb.DMatrix(X_train,label=y_train)\n",
    "data_test=xgb.DMatrix(X_test)\n",
    "params={'booster':'gbtree','objective': 'binary:logistic',\n",
    "        'gamma':0.15,'learning_rate' : 0.01}\n",
    "watchlist=[(data_train,'train')]\n",
    "model16=xgb.train(params,data_train,num_boost_round=5,evals=watchlist)\n",
    "y_pred=model16.predict(data_test)\n",
    "y_pred=(y_pred>=0.5)*1\n",
    "# 由于本案例是分类任务，故采用精度指标进行评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc=accuracy_score(y_pred,y_test)\n",
    "print(\"XGBoost模型拟合的准确率为:%.3f%%\"% (Acc *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeaveOneOut()\n",
      "TRAIN: [1] TEST: [0]\n",
      "[[3 4]] [[1 2]] [2] [1]\n",
      "TRAIN: [0] TEST: [1]\n",
      "[[1 2]] [[3 4]] [1] [2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "X = np.array([[1, 2], [3, 4]])\n",
    "y = np.array([1, 2])\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)\n",
    "print(loo)\n",
    "for train_index, test_index in loo.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adaptive_LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AdaptiveLasso' from 'sklearn.linear_model' (D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d6071b891f1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdaptiveLasso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AdaptiveLasso' from 'sklearn.linear_model' (D:\\Users\\kw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\__init__.py)"
     ]
    }
   ],
   "source": [
    "def Adaptive_LASSO(X_train,y_train,max_iterations = 1000,lasso_iterations = 10, alpha = 0.1, tol = 0.001, max_error_up = 5, title = ''):\n",
    "    \n",
    "    # set checks\n",
    "    higher  = float('inf')\n",
    "    lower   = 0\n",
    "    \n",
    "    # set lists\n",
    "    coefficients_list = []\n",
    "    iterations_list   = []\n",
    "    \n",
    "    # set variables\n",
    "    X_train  = X_train\n",
    "    y_train  = y_train\n",
    "    \n",
    "    # set constants\n",
    "    alpha    = alpha\n",
    "    tol      = tol\n",
    "    max_iter = max_iterations\n",
    "    n_lasso_iterations = lasso_iterations\n",
    "    \n",
    "    g = lambda w: np.sqrt(np.abs(w))\n",
    "    gprime = lambda w: 1. / (2. * np.sqrt(np.abs(w)) + np.finfo(float).eps)\n",
    "\n",
    "    n_samples, n_features = X_train.shape\n",
    "    p_obj = lambda w: 1. / (2 * n_samples) * np.sum((y_train - np.dot(X_train, w)) ** 2) \\\n",
    "                      + alpha * np.sum(g(w))\n",
    "\n",
    "    weights = np.ones(n_features)\n",
    "\n",
    "    X_w = X_train / weights[np.newaxis, :]\n",
    "    X_w  = np.nan_to_num(X_w)\n",
    "    X_w  = np.round(X_w,decimals = 3)\n",
    "\n",
    "    y_train    = np.nan_to_num(y_train)\n",
    "\n",
    "    adaptive_lasso = Lasso(alpha=alpha, fit_intercept=False)\n",
    "\n",
    "    adaptive_lasso.fit(X_w, y_train)\n",
    "\n",
    "    for k in range(n_lasso_iterations):\n",
    "        X_w = X_train / weights[np.newaxis, :]\n",
    "        adaptive_lasso = Lasso(alpha=alpha, fit_intercept=False)\n",
    "        adaptive_lasso.fit(X_w, y_train)\n",
    "        coef_ = adaptive_lasso.coef_ / weights\n",
    "        weights = gprime(coef_)\n",
    "        \n",
    "        print ('Iteration #',k+1,':   ',p_obj(coef_))  # should go down\n",
    "        \n",
    "        iterations_list.append(k)\n",
    "        coefficients_list.append(p_obj(coef_))\n",
    "        \n",
    "    print (np.mean((adaptive_lasso.coef_ != 0.0) == (coef_ != 0.0)))   \n",
    "    \n",
    "    coef = pd.Series(adaptive_lasso.coef_, index = X_train.columns)\n",
    "    print('=============================================================================')\n",
    "    print(\"Adaptive LASSO picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables.\")\n",
    "    print('=============================================================================')\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (18,8)\n",
    "\n",
    "    # subplot of the predicted vs. actual\n",
    "\n",
    "    plt.plot(iterations_list,coefficients_list,color = 'orange')\n",
    "    plt.scatter(iterations_list,coefficients_list,color = 'green')\n",
    "    plt.title('Iterations vs. p_obj(coef_)')\n",
    "    plt.show()\n",
    "\n",
    "    # plot of the coefficients'\n",
    "\n",
    "    imp_coef = pd.concat([coef.sort_values().head(10),coef.sort_values().tail(10)])\n",
    "    imp_coef.plot(kind = \"barh\", color = 'green',  fontsize=14)\n",
    "    plt.title(\"Top and Botton 10 Coefficients Selected by the Adaptive LASSO Model\", fontsize = 14)\n",
    "    plt.show()\n",
    "    return adaptive_lasso\n",
    "\n",
    "# variable selection with LASSO for the model\n",
    "\n",
    "#y_train = numbers_df['y']\n",
    "#X_train = numbers_df[[col for col in numbers_df.columns if col != 'y']]\n",
    "\n",
    "#model = Adaptive_LASSO(X_train,\n",
    "#                       y_train,\n",
    "#                       max_iterations = 1000,\n",
    "#                       lasso_iterations = 10, \n",
    "#                       alpha = 0.1, \n",
    "#                       tol = 0.001, \n",
    "#                       max_error_up = 5, \n",
    "#                       title = '')\n",
    "\n",
    "# look at the coefficients in the model\n",
    "\n",
    "#coef = pd.Series(model.coef_, index = X_train.columns)\n",
    "#coef = pd.DataFrame(coef).reset_index()\n",
    "#coef_list = coef.loc[coef[0]!= 0.0]['index'].to_list()\n",
    "#new_X_train = X_train[coef_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-99f4fc02d64e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madaptive_LASSO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "adaptive_LASSO(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFNetwork:\n",
    "    def __init__(self, no_of_input, no_of_hidden, no_of_output, data):\n",
    "        self.no_of_input = no_of_input\n",
    "        self.no_of_hidden = no_of_hidden\n",
    "        self.no_of_output = no_of_output\n",
    "        self.data = data\n",
    "        self.input = np.zeros(self.no_of_input)\n",
    "        self.centroid = np.zeros((self.no_of_hidden, self.no_of_input))\n",
    "        self.sigma = np.zeros(self.no_of_hidden)\n",
    "        self.hidden_output = np.zeros(self.no_of_hidden)\n",
    "        self.hidden_to_output_weight = np.zeros((self.no_of_hidden, self.no_of_output))\n",
    "        self.output = np.zeros(self.no_of_output)\n",
    "        self.output_bias = np.zeros(self.no_of_output)\n",
    "        self.actual_target_values = []\n",
    "        self.total = 0\n",
    "        self.learningRate = 0.0262\n",
    "        self.setup_center()\n",
    "        self.setup_sigma_spread_radius()\n",
    "        self.set_up_hidden_to_ouput_weight()\n",
    "        self.set_up_output_bias()\n",
    "\n",
    "    def setup_center(self):\n",
    "        \"\"\"Setup center using clustering ,for now just randomize between 0 and 1\"\"\"\n",
    "        # print(\"Setup center\")\n",
    "        for i in range(self.no_of_hidden):\n",
    "            self.centroid[i] = np.random.uniform(0, 1, self.no_of_input)\n",
    "\n",
    "    def setup_sigma_spread_radius(self):\n",
    "        # print(\"Setup Sigma spread radius\")\n",
    "        for i in range(self.no_of_hidden):\n",
    "            center = self.centroid[i]\n",
    "            self.sigma[i] = self.set_up_sigma_for_center(center)\n",
    "            # print(\"Sigma i\",i, self.sigma[i])\n",
    "\n",
    "    def set_up_sigma_for_center(self, center):\n",
    "        # print(\"Get sigma for center\")\n",
    "        p = self.no_of_hidden / 3\n",
    "        sigma = 0\n",
    "        distances = [0 for i in range(self.no_of_hidden)]\n",
    "        for i in range(self.no_of_hidden):\n",
    "            distances[i] = self.euclidean_distance(center, self.centroid[i])\n",
    "            # print(\"Distance \", i, distances[i])\n",
    "        sum = 0\n",
    "        for i in range(int(p)):\n",
    "            nearest = self.get_smallest_index(distances)\n",
    "            distances[nearest] = float(\"inf\")\n",
    "\n",
    "            neighbour_centroid = self.centroid[nearest]\n",
    "            for j in range(len(neighbour_centroid)):\n",
    "                sum += (center[j] - neighbour_centroid[j]) ** 2\n",
    "\n",
    "        sigma = sum / p\n",
    "        sigma = math.sqrt(sigma)\n",
    "        #return random.uniform(0, 1) * 6\n",
    "        return sigma\n",
    "\n",
    "    @staticmethod\n",
    "    def euclidean_distance( x, y):\n",
    "        return np.linalg.norm(x-y)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_smallest_index( distances):\n",
    "        min_index = 0\n",
    "        for i in range(len(distances)):\n",
    "            if (distances[min_index] > distances[i]):\n",
    "                min_index = i\n",
    "        return min_index\n",
    "\n",
    "    def set_up_hidden_to_ouput_weight(self):\n",
    "        print(\"Setup hidden to output weight\")\n",
    "        self.hidden_to_output_weight = np.random.uniform(0, 1, (self.no_of_hidden, self.no_of_output))\n",
    "\n",
    "        print(\"Hiden to output weight \", self.hidden_to_output_weight)\n",
    "\n",
    "    def set_up_output_bias(self):\n",
    "        print(\"Setup output bias\")\n",
    "        self.output_bias = np.random.uniform(0, 1, self.no_of_output)\n",
    "\n",
    "    # train n iteration\n",
    "    def train(self, n):\n",
    "        for i in range(n):\n",
    "            error = self.pass_one_epoch()\n",
    "            print(\"Iteration \", i, \" Error \", error)\n",
    "\n",
    "        return error\n",
    "\n",
    "    # Train an epoch and return total MSE\n",
    "    def pass_one_epoch(self):\n",
    "        # print(\"Pass one epoch\")\n",
    "        all_error = 0\n",
    "        all_index = []\n",
    "        for i in range(len(self.data.patterns)):\n",
    "            all_index.append(i)\n",
    "        # print(\"All index \",all_index)\n",
    "\n",
    "        for i in range(len(self.data.patterns)):\n",
    "            random_index = (int)(random.uniform(0, 1) * len(all_index))\n",
    "            # print(\"Random index \",random_index, \" Len \", len(all_index))\n",
    "            \"\"\"Get a random pattern to train\"\"\"\n",
    "            pattern = self.data.patterns[random_index]\n",
    "            del all_index[random_index]\n",
    "\n",
    "            input = pattern.input\n",
    "            self.actual_target_values = pattern.output\n",
    "            self.pass_input_to_network(input)\n",
    "\n",
    "            error = self.get_error_for_pattern()\n",
    "            all_error += error\n",
    "            self.gradient_descent()\n",
    "\n",
    "        all_error = all_error / (len(self.data.patterns))\n",
    "        return all_error\n",
    "\n",
    "    def pass_input_to_network(self, input):\n",
    "        self.input = input\n",
    "        self.pass_to_hidden_node()\n",
    "        self.pass_to_output_node()\n",
    "\n",
    "    def pass_to_hidden_node(self):\n",
    "        # print(\"Pass to hidden node\")\n",
    "        self.hidden_output = np.zeros(self.no_of_hidden)\n",
    "        for i in range(len(self.hidden_output)):\n",
    "            euclid_distance = self.euclidean_distance(self.input, self.centroid[i]) ** 2\n",
    "            self.hidden_output[i] = math.exp(- (euclid_distance / (2 * self.sigma[i] * self.sigma[i])))\n",
    "\n",
    "            # print(\"Hdiden node output \",self.hidden_output)\n",
    "\n",
    "    def pass_to_output_node(self):\n",
    "        # print(\"Pass to output node\")\n",
    "        self.output = [0 for i in range(self.no_of_output)]\n",
    "        total = 0\n",
    "        for i in range(self.no_of_output):\n",
    "            output_value = 0\n",
    "            for j in range(self.no_of_hidden):\n",
    "                self.output[i] += self.hidden_to_output_weight[j][i] * self.hidden_output[j]\n",
    "        \"\"\"Normalize \"\"\"\n",
    "        for i in range(self.no_of_output):\n",
    "            total += self.output[i]\n",
    "        for i in range(self.no_of_output):\n",
    "            if (self.output[i] != 0):\n",
    "                self.output[i] = self.output[i] / total\n",
    "        self.total = total\n",
    "\n",
    "    # Compute error for the pattern\n",
    "    def get_error_for_pattern(self):\n",
    "        error = 0\n",
    "        for i in range(len(self.output)):\n",
    "            error += (self.actual_target_values[i] - self.output[i]) ** 2\n",
    "        return error\n",
    "\n",
    "    # Weight update by gradient descent algorithm\n",
    "    def gradient_descent(self):\n",
    "        # compute the error of output layer\n",
    "        self.mean_error = 0\n",
    "        self.error_of_output_layer = [0 for i in range(self.no_of_output)]\n",
    "        for i in range(self.no_of_output):\n",
    "            self.error_of_output_layer[i] = (float)(self.actual_target_values[i] - self.output[i])\n",
    "            e = (float)(self.actual_target_values[i] - self.output[i]) ** 2 * 0.5\n",
    "            self.mean_error += e\n",
    "\n",
    "        # Adjust hidden to output weight\n",
    "        for o in range(self.no_of_output):\n",
    "            for h in range(self.no_of_hidden):\n",
    "                delta_weight = self.learningRate * self.error_of_output_layer[o] * self.hidden_output[h]\n",
    "                self.hidden_to_output_weight[h][o] += delta_weight\n",
    "\n",
    "        # For bias\n",
    "        for o in range(self.no_of_output):\n",
    "            delta_bias = self.learningRate * self.error_of_output_layer[o]\n",
    "            self.output_bias[o] += delta_bias\n",
    "\n",
    "        # Adjust center , input to hidden weight\n",
    "        for i in range(self.no_of_input):\n",
    "            for j in range(self.no_of_hidden):\n",
    "                summ = 0\n",
    "                for p in range(self.no_of_output):\n",
    "                    summ += self.hidden_to_output_weight[j][p] * (self.actual_target_values[p] - self.output[p])\n",
    "\n",
    "                second_part = (float)((self.input[i] - self.centroid[j][i]) / math.pow(self.sigma[j], 2))\n",
    "                delta_weight = (float)(self.learningRate * self.hidden_output[j] * second_part * summ)\n",
    "                self.centroid[j][i] += delta_weight\n",
    "\n",
    "        # Adjust sigma and spread radius\n",
    "        for i in range(self.no_of_input):\n",
    "            for j in range(self.no_of_hidden):\n",
    "                summ = 0\n",
    "                for p in range(self.no_of_output):\n",
    "                    summ += self.hidden_to_output_weight[j][p] * (self.actual_target_values[p] - self.output[p])\n",
    "\n",
    "                second_part = (float)(\n",
    "                    (math.pow((self.input[i] - self.centroid[j][i]), 2)) / math.pow(self.sigma[j], 3));\n",
    "                delta_weight = (float)(0.1 * self.learningRate * self.hidden_output[j] * second_part * summ);\n",
    "                self.sigma[j] += delta_weight\n",
    "        return self.mean_error\n",
    "\n",
    "    def get_accuracy_for_training(self):\n",
    "        correct = 0\n",
    "        for i in range(len(self.data.patterns)):\n",
    "            pattern = self.data.patterns[i]\n",
    "            self.pass_input_to_network(pattern.input)\n",
    "            n_output = self.output\n",
    "            act_output = pattern.output\n",
    "            n_neuron = self.get_fired_neuron(n_output)\n",
    "            a_neuron = self.get_fired_neuron(act_output)\n",
    "\n",
    "            if n_neuron == a_neuron:\n",
    "                correct += 1\n",
    "        accuracy = (float)(correct / len(self.data.patterns)) * 100\n",
    "        return accuracy\n",
    "\n",
    "    def get_fired_neuron(self, output):\n",
    "        max = 0\n",
    "        for i in range(len(output)):\n",
    "            if (output[i] > output[max]):\n",
    "                max = i\n",
    "        return max\n",
    "\n",
    "\n",
    "\"\"\"Create test data \"\"\"\n",
    "p1 = Pattern(1, [0, 0], [1, 0])\n",
    "p2 = Pattern(2, [0, 1], [0, 1])\n",
    "p3 = Pattern(3, [1, 0], [0, 1])\n",
    "p4 = Pattern(4, [1, 1], [1, 0])\n",
    "\n",
    "patterns = [p1, p2, p3, p4]\n",
    "classLabels = ['0', '1']\n",
    "data = Data(patterns, classLabels)\n",
    "rbf = RBFNetwork(2, 6, 2, data)\n",
    "mse = rbf.train(1500)\n",
    "accuracy = rbf.get_accuracy_for_training()\n",
    "print(\"Total accuracy is \", accuracy)\n",
    "print(\"Last MSE \",mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondad8faa91d1f494fd1bc5bfb220e602d60"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
